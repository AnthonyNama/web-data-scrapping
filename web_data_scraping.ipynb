{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web data scraping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3rpjQ9RHVJkOM/sJJxopM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnthonyNama/web-data-scrapping/blob/master/web_data_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwOukyv0wRwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y5EPuATW-Aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKzYS5sdxIVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWsMOdJhWrA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caxXPQnt2ZQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import HTML"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owy1mBbgXFk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_URL = 'https://arxiv.org'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRhisVG0c5BN",
        "colab_type": "text"
      },
      "source": [
        "**Computer vison and pattern recognition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOjHGpKQXabA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://arxiv.org/list/cs.CV/new'\n",
        "html_doc = requests.get(url).text\n",
        "soup = BeautifulSoup(html_doc, \"html.parser\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Tal9Pqc1BA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submissionCV = [div.get_text() for div in soup.find_all('div') if 'class' in div.attrs and div.attrs['class'] == ['list-dateline']][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7yqDp1teJR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linksCV = [BASE_URL + link.get('href') for link in soup.find_all(\"a\") if 'title' in link.attrs and link.attrs['title'] == 'Abstract']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8zCs5pjevTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titlesCV = [div.get_text()[8:][:-1] for div in soup.find_all(\"div\") if 'class' in div.attrs and div.attrs['class'] == ['list-title', 'mathjax']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNET1pdJig18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abstractsCV = []\n",
        "for div in soup.find_all(\"div\"):\n",
        "    if 'class' in div.attrs and div.attrs['class'] == ['meta']:\n",
        "        if div.p != None:\n",
        "            abstractsCV.append(div.p.get_text())\n",
        "        else:\n",
        "            abstractsCV.append(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnlw-7nru186",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "Filters what I want\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2wtAIfHuzjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_keywordsCV = [\"GAN\", \"Capsule\"]  # This is an example"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLwg5edvwKAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2681cb2-c9d1-4f1a-dcd0-8dad312f729d"
      },
      "source": [
        "print(submissionCV)"
      ],
      "execution_count": 419,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submissions received from  Wed  8 Apr 20  to  Thu  9 Apr 20, announced Fri, 10 Apr 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHB2hcZiwNWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CV = pd.DataFrame({'Title': titlesCV, 'Abstract': abstractsCV, 'Link': linksCV})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOv6dcBVyc3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "429134cf-f863-481c-f62a-3e7afa31e068"
      },
      "source": [
        "CV"
      ],
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Leveraging 2D Data to Learn Textured 3D Mesh G...</td>\n",
              "      <td>Numerous methods have been proposed for probab...</td>\n",
              "      <td>https://arxiv.org/abs/2004.04180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The GeoLifeCLEF 2020 Dataset</td>\n",
              "      <td>Understanding the geographic distribution of s...</td>\n",
              "      <td>https://arxiv.org/abs/2004.04192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Transferable, Controllable, and Inconspicuous ...</td>\n",
              "      <td>The success of DNNs has driven the extensive a...</td>\n",
              "      <td>https://arxiv.org/abs/2004.04199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Deep Manifold Prior</td>\n",
              "      <td>We present a prior for manifold structured dat...</td>\n",
              "      <td>https://arxiv.org/abs/2004.04242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Estimating Grape Yield on the Vine from Multip...</td>\n",
              "      <td>Estimating grape yield prior to harvest is imp...</td>\n",
              "      <td>https://arxiv.org/abs/2004.04278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>A Physics-based Noise Formation Model for Extr...</td>\n",
              "      <td></td>\n",
              "      <td>https://arxiv.org/abs/2003.12751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>How Not to Give a FLOP: Combining Regularizati...</td>\n",
              "      <td></td>\n",
              "      <td>https://arxiv.org/abs/2003.13593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>Manifold-Aware CycleGAN for High Resolution St...</td>\n",
              "      <td></td>\n",
              "      <td>https://arxiv.org/abs/2004.00173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>Evolving Normalization-Activation Layers</td>\n",
              "      <td></td>\n",
              "      <td>https://arxiv.org/abs/2004.02967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>A Polynomial Neural Network with Controllable ...</td>\n",
              "      <td></td>\n",
              "      <td>https://arxiv.org/abs/2004.03955</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Title  ...                              Link\n",
              "0   Leveraging 2D Data to Learn Textured 3D Mesh G...  ...  https://arxiv.org/abs/2004.04180\n",
              "1                        The GeoLifeCLEF 2020 Dataset  ...  https://arxiv.org/abs/2004.04192\n",
              "2   Transferable, Controllable, and Inconspicuous ...  ...  https://arxiv.org/abs/2004.04199\n",
              "3                                 Deep Manifold Prior  ...  https://arxiv.org/abs/2004.04242\n",
              "4   Estimating Grape Yield on the Vine from Multip...  ...  https://arxiv.org/abs/2004.04278\n",
              "..                                                ...  ...                               ...\n",
              "85  A Physics-based Noise Formation Model for Extr...  ...  https://arxiv.org/abs/2003.12751\n",
              "86  How Not to Give a FLOP: Combining Regularizati...  ...  https://arxiv.org/abs/2003.13593\n",
              "87  Manifold-Aware CycleGAN for High Resolution St...  ...  https://arxiv.org/abs/2004.00173\n",
              "88           Evolving Normalization-Activation Layers  ...  https://arxiv.org/abs/2004.02967\n",
              "89  A Polynomial Neural Network with Controllable ...  ...  https://arxiv.org/abs/2004.03955\n",
              "\n",
              "[90 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 421
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mum3IxA1yFKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CV = pd.DataFrame({'Title': titlesCV, 'Abstract': abstractsCV, 'Link': linksCV})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flIYBKCF6Py-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d29b65c4-3044-457c-b6f4-05fcd813522b"
      },
      "source": [
        "CV.shape"
      ],
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le1Ejo1V6Z4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, row in CV.iterrows():\n",
        "    x = []\n",
        "    for keyword in my_keywordsCV:\n",
        "        x = x + re.findall(keyword, row['Title'] + row['Abstract'])\n",
        "    if not x:\n",
        "        CV.drop([i], axis=0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkr_Hnb_6o-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "outputId": "d3181f9e-98f8-456c-9773-441045680b50"
      },
      "source": [
        "CV.style.format({\"Link\": lambda x: '<a href=\"{}\">{}</a>'.format(x, x)})"
      ],
      "execution_count": 425,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Title</th>        <th class=\"col_heading level0 col1\" >Abstract</th>        <th class=\"col_heading level0 col2\" >Link</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >10</th>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row0_col0\" class=\"data row0 col0\" >Masked GANs for Unsupervised Depth and Pose Prediction with Scale  Consistency</td>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row0_col1\" class=\"data row0 col1\" >Previous works have shown that adversarial learning can be used for\n",
              "unsupervised monocular depth and visual odometry (VO) estimation. However, the\n",
              "performance of pose and depth networks is limited by occlusions and visual\n",
              "field changes. Because of the incomplete correspondence of visual information\n",
              "between frames caused by motion, target images cannot be synthesized completely\n",
              "from source images via view reconstruction and bilinear interpolation. The\n",
              "reconstruction loss based on the difference between synthesized and real target\n",
              "images will be affected by the incomplete reconstruction. Besides, the data\n",
              "distribution of unreconstructed regions will be learned and help the\n",
              "discriminator distinguish between real and fake images, thereby causing the\n",
              "case that the generator may fail to compete with the discriminator. Therefore,\n",
              "a MaskNet is designed in this paper to predict these regions and reduce their\n",
              "impacts on the reconstruction loss and adversarial loss. The impact of\n",
              "unreconstructed regions on discriminator is tackled by proposing a boolean mask\n",
              "scheme, as shown in Fig. 1. Furthermore, we consider the scale consistency of\n",
              "our pose network by utilizing a new scale-consistency loss, therefore our pose\n",
              "network is capable of providing the full camera trajectory over the long\n",
              "monocular sequence. Extensive experiments on KITTI dataset show that each\n",
              "component proposed in this paper contributes to the performance, and both of\n",
              "our depth and trajectory prediction achieve competitive performance.\n",
              "</td>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row0_col2\" class=\"data row0 col2\" ><a href=\"https://arxiv.org/abs/2004.04345\">https://arxiv.org/abs/2004.04345</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >28</th>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row1_col0\" class=\"data row1 col0\" >TuiGAN: Learning Versatile Image-to-Image Translation with Two Unpaired  Images</td>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row1_col1\" class=\"data row1 col1\" >An unsupervised image-to-image translation (UI2I) task deals with learning a\n",
              "mapping between two domains without paired images. While existing UI2I methods\n",
              "usually require numerous unpaired images from different domains for training,\n",
              "there are many scenarios where training data is quite limited. In this paper,\n",
              "we argue that even if each domain contains a single image, UI2I can still be\n",
              "achieved. To this end, we propose TuiGAN, a generative model that is trained on\n",
              "only two unpaired images and amounts to one-shot unsupervised learning. With\n",
              "TuiGAN, an image is translated in a coarse-to-fine manner where the generated\n",
              "image is gradually refined from global structures to local details. We conduct\n",
              "extensive experiments to verify that our versatile method can outperform strong\n",
              "baselines on a wide variety of UI2I tasks. Moreover, TuiGAN is capable of\n",
              "achieving comparable performance with the state-of-the-art UI2I models trained\n",
              "with sufficient data.\n",
              "</td>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row1_col2\" class=\"data row1 col2\" ><a href=\"https://arxiv.org/abs/2004.04634\">https://arxiv.org/abs/2004.04634</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >33</th>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row2_col0\" class=\"data row2 col0\" >Inpainting via Generative Adversarial Networks for CMB data analysis</td>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row2_col1\" class=\"data row2 col1\" >In this work, we propose a new method to inpaint the CMB signal in regions\n",
              "masked out following a point source extraction process. We adopt a modified\n",
              "Generative Adversarial Network (GAN) and compare different combinations of\n",
              "internal (hyper-)parameters and training strategies. We study the performance\n",
              "using a suitable $\\mathcal{C}_r$ variable in order to estimate the performance\n",
              "regarding the CMB power spectrum recovery. We consider a test set where one\n",
              "point source is masked out in each sky patch with a 1.83 $\\times$ 1.83 squared\n",
              "degree extension, which, in our gridding, corresponds to 64 $\\times$ 64 pixels.\n",
              "The GAN is optimized for estimating performance on Planck 2018 total intensity\n",
              "simulations. The training makes the GAN effective in reconstructing a masking\n",
              "corresponding to about 1500 pixels with $1\\%$ error down to angular scales\n",
              "corresponding to about 5 arcminutes.\n",
              "</td>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row2_col2\" class=\"data row2 col2\" ><a href=\"https://arxiv.org/abs/2004.04177\">https://arxiv.org/abs/2004.04177</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >40</th>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row3_col0\" class=\"data row3 col0\" >Score-Guided Generative Adversarial Networks</td>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row3_col1\" class=\"data row3 col1\" >We propose a Generative Adversarial Network (GAN) that introduces an\n",
              "evaluator module using pre-trained networks. The proposed model, called\n",
              "score-guided GAN (ScoreGAN), is trained with an evaluation metric for GANs,\n",
              "i.e., the Inception score, as a rough guide for the training of the generator.\n",
              "By using another pre-trained network instead of the Inception network, ScoreGAN\n",
              "circumvents the overfitting of the Inception network in order that generated\n",
              "samples do not correspond to adversarial examples of the Inception network.\n",
              "Also, to prevent the overfitting, the evaluation metrics are employed only as\n",
              "an auxiliary role, while the conventional target of GANs is mainly used.\n",
              "Evaluated with the CIFAR-10 dataset, ScoreGAN demonstrated an Inception score\n",
              "of 10.36$\\pm$0.15, which corresponds to state-of-the-art performance.\n",
              "Furthermore, to generalize the effectiveness of ScoreGAN, the model was further\n",
              "evaluated with another dataset, i.e., the CIFAR-100; as a result, ScoreGAN\n",
              "outperformed the other existing methods, where the Fr\\'echet Inception Distance\n",
              "(FID) of ScoreGAN trained over the CIFAR-100 dataset was 13.98.\n",
              "</td>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row3_col2\" class=\"data row3 col2\" ><a href=\"https://arxiv.org/abs/2004.04396\">https://arxiv.org/abs/2004.04396</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >43</th>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row4_col0\" class=\"data row4 col0\" >Adversarial Latent Autoencoders</td>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row4_col1\" class=\"data row4 col1\" >Autoencoder networks are unsupervised approaches aiming at combining\n",
              "generative and representational properties by learning simultaneously an\n",
              "encoder-generator map. Although studied extensively, the issues of whether they\n",
              "have the same generative power of GANs, or learn disentangled representations,\n",
              "have not been fully addressed. We introduce an autoencoder that tackles these\n",
              "issues jointly, which we call Adversarial Latent Autoencoder (ALAE). It is a\n",
              "general architecture that can leverage recent improvements on GAN training\n",
              "procedures. We designed two autoencoders: one based on a MLP encoder, and\n",
              "another based on a StyleGAN generator, which we call StyleALAE. We verify the\n",
              "disentanglement properties of both architectures. We show that StyleALAE can\n",
              "not only generate 1024x1024 face images with comparable quality of StyleGAN,\n",
              "but at the same resolution can also produce face reconstructions and\n",
              "manipulations based on real images. This makes ALAE the first autoencoder able\n",
              "to compare with, and go beyond the capabilities of a generator-only type of\n",
              "architecture.\n",
              "</td>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row4_col2\" class=\"data row4 col2\" ><a href=\"https://arxiv.org/abs/2004.04467\">https://arxiv.org/abs/2004.04467</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >87</th>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row5_col0\" class=\"data row5 col0\" >Manifold-Aware CycleGAN for High Resolution Structural-to-DTI Synthesis</td>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row5_col1\" class=\"data row5 col1\" ></td>\n",
              "                        <td id=\"T_839ef886_7c32_11ea_8655_0242ac1c0002row5_col2\" class=\"data row5 col2\" ><a href=\"https://arxiv.org/abs/2004.00173\">https://arxiv.org/abs/2004.00173</a></td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fd7d71a2f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 425
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EFgw82TntN5",
        "colab_type": "text"
      },
      "source": [
        "**Machine learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJSulkVUdEdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://arxiv.org/list/cs.LG/new'\n",
        "html_doc = requests.get(url).text\n",
        "soup = BeautifulSoup(html_doc, \"html.parser\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vfwvJpXrgCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submissionLG = [div.get_text() for div in soup.find_all('div') if 'class' in div.attrs and div.attrs['class'] == ['list-dateline']][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JygGKffBru_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linksLG = [BASE_URL + link.get('href') for link in soup.find_all(\"a\") if 'title' in link.attrs and link.attrs['title'] == 'Abstract']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJS3eQ5Dry1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titlesLG = [div.get_text()[8:][:-1] for div in soup.find_all(\"div\") if 'class' in div.attrs and div.attrs['class'] == ['list-title', 'mathjax']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnjOe3vOr8iV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abstractsLG = []\n",
        "for div in soup.find_all(\"div\"):\n",
        "    if 'class' in div.attrs and div.attrs['class'] == ['meta']:\n",
        "        if div.p != None:\n",
        "            abstractsLG.append(div.p.get_text())\n",
        "        else:\n",
        "            abstractsLG.append(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUNtpdDlu9z8",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "Filters what I want\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3R-tQc6sbMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_keywordsLG = ['natural language processing', 'text mining', \"NLP\", \"question answering\", \"spectral methods\", \"SVD\"]  # This is an example"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2RaXmoxwEHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2bae2497-cedc-41f9-9a41-4d4518c9d913"
      },
      "source": [
        "print(submissionLG)"
      ],
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submissions received from  Wed  8 Apr 20  to  Thu  9 Apr 20, announced Fri, 10 Apr 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab2H1-bPzDI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LG = pd.DataFrame({'Title': titlesLG, 'Abstract': abstractsLG, 'Link': linksLG})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13oHNvbj2nWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c713bd3-5897-486b-d0c3-fff648fa1eba"
      },
      "source": [
        "LG.style.format({\"Link\": lambda x: '<a href=\"{}\">{}</a>'.format(x, x)})"
      ],
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Title</th>        <th class=\"col_heading level0 col1\" >Abstract</th>        <th class=\"col_heading level0 col2\" >Link</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row0_col0\" class=\"data row0 col0\" >Saliency-based Weighted Multi-label Linear Discriminant Analysis</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row0_col1\" class=\"data row0 col1\" >In this paper, we propose a new variant of Linear Discriminant Analysis (LDA)\n",
              "to solve multi-label classification tasks. The proposed method is based on a\n",
              "probabilistic model for defining the weights of individual samples in a\n",
              "weighted multi-label LDA approach. Linear Discriminant Analysis is a classical\n",
              "statistical machine learning method, which aims to find a linear data\n",
              "transformation increasing class discrimination in an optimal discriminant\n",
              "subspace. Traditional LDA sets assumptions related to Gaussian class\n",
              "distributions and single-label data annotations. To employ the LDA technique in\n",
              "multi-label classification problems, we exploit intuitions coming from a\n",
              "probabilistic interpretation of class saliency to redefine the between-class\n",
              "and within-class scatter matrices. The saliency-based weights obtained based on\n",
              "various kinds of affinity encoding prior information are used to reveal the\n",
              "probability of each instance to be salient for each of its classes in the\n",
              "multi-label problem at hand. The proposed Saliency-based weighted Multi-label\n",
              "LDA approach is shown to lead to performance improvements in various\n",
              "multi-label classification problems.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row0_col2\" class=\"data row0 col2\" ><a href=\"https://arxiv.org/abs/2004.04221\">https://arxiv.org/abs/2004.04221</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row1_col0\" class=\"data row1 col0\" >GeneCAI: Genetic Evolution for Acquiring Compact AI</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row1_col1\" class=\"data row1 col1\" >In the contemporary big data realm, Deep Neural Networks (DNNs) are evolving\n",
              "towards more complex architectures to achieve higher inference accuracy. Model\n",
              "compression techniques can be leveraged to efficiently deploy such\n",
              "compute-intensive architectures on resource-limited mobile devices. Such\n",
              "methods comprise various hyper-parameters that require per-layer customization\n",
              "to ensure high accuracy. Choosing such hyper-parameters is cumbersome as the\n",
              "pertinent search space grows exponentially with model layers. This paper\n",
              "introduces GeneCAI, a novel optimization method that automatically learns how\n",
              "to tune per-layer compression hyper-parameters. We devise a bijective\n",
              "translation scheme that encodes compressed DNNs to the genotype space. The\n",
              "optimality of each genotype is measured using a multi-objective score based on\n",
              "accuracy and number of floating point operations. We develop customized genetic\n",
              "operations to iteratively evolve the non-dominated solutions towards the\n",
              "optimal Pareto front, thus, capturing the optimal trade-off between model\n",
              "accuracy and complexity. GeneCAI optimization method is highly scalable and can\n",
              "achieve a near-linear performance boost on distributed multi-GPU platforms. Our\n",
              "extensive evaluations demonstrate that GeneCAI outperforms existing rule-based\n",
              "and reinforcement learning methods in DNN compression by finding models that\n",
              "lie on a better accuracy-complexity Pareto curve.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row1_col2\" class=\"data row1 col2\" ><a href=\"https://arxiv.org/abs/2004.04249\">https://arxiv.org/abs/2004.04249</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row2_col0\" class=\"data row2 col0\" >Federated Multi-view Matrix Factorization for Personalized  Recommendations</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row2_col1\" class=\"data row2 col1\" >We introduce the federated multi-view matrix factorization method that\n",
              "extends the federated learning framework to matrix factorization with multiple\n",
              "data sources. Our method is able to learn the multi-view model without\n",
              "transferring the user's personal data to a central server. As far as we are\n",
              "aware this is the first federated model to provide recommendations using\n",
              "multi-view matrix factorization. The model is rigorously evaluated on three\n",
              "datasets on production settings. Empirical validation confirms that federated\n",
              "multi-view matrix factorization outperforms simpler methods that do not take\n",
              "into account the multi-view structure of the data, in addition, it demonstrates\n",
              "the usefulness of the proposed method for the challenging prediction tasks of\n",
              "cold-start federated recommendations.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row2_col2\" class=\"data row2 col2\" ><a href=\"https://arxiv.org/abs/2004.04256\">https://arxiv.org/abs/2004.04256</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row3_col0\" class=\"data row3 col0\" >Deep Learning and Open Set Malware Classification: A Survey</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row3_col1\" class=\"data row3 col1\" >As the Internet is growing rapidly these years, the variant of malicious\n",
              "software, which often referred to as malware, has become one of the major and\n",
              "serious threats to Internet users. The dramatic increase of malware has led to\n",
              "a research area of not only using cutting edge machine learning techniques\n",
              "classify malware into their known families, moreover, recognize the unknown\n",
              "ones, which can be related to Open Set Recognition (OSR) problem in machine\n",
              "learning. Recent machine learning works have shed light on Open Set Recognition\n",
              "(OSR) from different scenarios. Under the situation of missing unknown training\n",
              "samples, the OSR system should not only correctly classify the known classes,\n",
              "but also recognize the unknown class. This survey provides an overview of\n",
              "different deep learning techniques, a discussion of OSR and graph\n",
              "representation solutions and an introduction of malware classification systems.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row3_col2\" class=\"data row3 col2\" ><a href=\"https://arxiv.org/abs/2004.04272\">https://arxiv.org/abs/2004.04272</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row4_col0\" class=\"data row4 col0\" >Adaptive Stress Testing without Domain Heuristics using Go-Explore</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row4_col1\" class=\"data row4 col1\" >Recently, reinforcement learning (RL) has been used as a tool for finding\n",
              "failures in autonomous systems. During execution, the RL agents often rely on\n",
              "some domain-specific heuristic reward to guide them towards finding failures,\n",
              "but constructing such a heuristic may be difficult or infeasible. Without a\n",
              "heuristic, the agent may only receive rewards at the time of failure, or even\n",
              "rewards that guide it away from failures. For example, some approaches give\n",
              "rewards for taking more-likely actions, because we want to find more-likely\n",
              "failures. However, the agent may then learn to only take likely actions, and\n",
              "may not be able to find a failure at all. Consequently, the problem becomes a\n",
              "hard-exploration problem, where rewards do not aid exploration. A new\n",
              "algorithm, go-explore (GE), has recently set new records on benchmarks from the\n",
              "hard-exploration field. We apply GE to adaptive stress testing (AST), one\n",
              "example of an RL-based falsification approach that provides a way to search for\n",
              "the most-likely failure scenario. We simulate a scenario where an autonomous\n",
              "vehicle drives while a pedestrian is crossing the road. We demonstrate that GE\n",
              "is able to find failures without domain-specific heuristics, such as the\n",
              "distance between the car and the pedestrian, on scenarios that other RL\n",
              "techniques are unable to solve. Furthermore, inspired by the robustification\n",
              "phase of GE, we demonstrate that the backwards algorithm (BA) improves the\n",
              "failures found by other RL techniques.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row4_col2\" class=\"data row4 col2\" ><a href=\"https://arxiv.org/abs/2004.04292\">https://arxiv.org/abs/2004.04292</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row5_col0\" class=\"data row5 col0\" >Automated Content Grading Using Machine Learning</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row5_col1\" class=\"data row5 col1\" >Grading of examination papers is a hectic, time-labor intensive task and is\n",
              "often subjected to inefficiency and bias in checking. This research project is\n",
              "a primitive experiment in the automation of grading of theoretical answers\n",
              "written in exams by students in technical courses which yet had continued to be\n",
              "human graded. In this paper, we show how the algorithmic approach in machine\n",
              "learning can be used to automatically examine and grade theoretical content in\n",
              "exam answer papers. Bag of words, their vectors & centroids, and a few semantic\n",
              "and lexical text features have been used overall. Machine learning models have\n",
              "been implemented on datasets manually built from exams given by graduating\n",
              "students enrolled in technical courses. These models have been compared to show\n",
              "the effectiveness of each model.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row5_col2\" class=\"data row5 col2\" ><a href=\"https://arxiv.org/abs/2004.04300\">https://arxiv.org/abs/2004.04300</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row6_col0\" class=\"data row6 col0\" >TOG: Targeted Adversarial Objectness Gradient Attacks on Real-time  Object Detection Systems</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row6_col1\" class=\"data row6 col1\" >The rapid growth of real-time huge data capturing has pushed the deep\n",
              "learning and data analytic computing to the edge systems. Real-time object\n",
              "recognition on the edge is one of the representative deep neural network (DNN)\n",
              "powered edge systems for real-world mission-critical applications, such as\n",
              "autonomous driving and augmented reality. While DNN powered object detection\n",
              "edge systems celebrate many life-enriching opportunities, they also open doors\n",
              "for misuse and abuse. This paper presents three Targeted adversarial Objectness\n",
              "Gradient attacks, coined as TOG, which can cause the state-of-the-art deep\n",
              "object detection networks to suffer from object-vanishing, object-fabrication,\n",
              "and object-mislabeling attacks. We also present a universal objectness gradient\n",
              "attack to use adversarial transferability for black-box attacks, which is\n",
              "effective on any inputs with negligible attack time cost, low human\n",
              "perceptibility, and particularly detrimental to object detection edge systems.\n",
              "We report our experimental measurements using two benchmark datasets (PASCAL\n",
              "VOC and MS COCO) on two state-of-the-art detection algorithms (YOLO and SSD).\n",
              "The results demonstrate serious adversarial vulnerabilities and the compelling\n",
              "need for developing robust object detection systems.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row6_col2\" class=\"data row6 col2\" ><a href=\"https://arxiv.org/abs/2004.04320\">https://arxiv.org/abs/2004.04320</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row7_col0\" class=\"data row7 col0\" >A Brief Prehistory of Double Descent</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row7_col1\" class=\"data row7 col1\" >In their thought-provoking paper [1], Belkin et al. illustrate and discuss\n",
              "the shape of risk curves in the context of modern high-complexity learners.\n",
              "Given a fixed training sample size $n$, such curves show the risk of a learner\n",
              "as a function of some (approximate) measure of its complexity $N$. With $N$ the\n",
              "number of features, these curves are also referred to as feature curves. A\n",
              "salient observation in [1] is that these curves can display, what they call,\n",
              "double descent: with increasing $N$, the risk initially decreases, attains a\n",
              "minimum, and then increases until $N$ equals $n$, where the training data is\n",
              "fitted perfectly. Increasing $N$ even further, the risk decreases a second and\n",
              "final time, creating a peak at $N=n$. This twofold descent may come as a\n",
              "surprise, but as opposed to what [1] reports, it has not been overlooked\n",
              "historically. Our letter draws attention to some original, earlier findings, of\n",
              "interest to contemporary machine learning.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row7_col2\" class=\"data row7 col2\" ><a href=\"https://arxiv.org/abs/2004.04328\">https://arxiv.org/abs/2004.04328</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row8_col0\" class=\"data row8 col0\" >HopGAT: Hop-aware Supervision Graph Attention Networks for Sparsely  Labeled Graphs</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row8_col1\" class=\"data row8 col1\" >Due to the cost of labeling nodes, classifying a node in a sparsely labeled\n",
              "graph while maintaining the prediction accuracy deserves attention. The key\n",
              "point is how the algorithm learns sufficient information from more neighbors\n",
              "with different hop distances. This study first proposes a hop-aware attention\n",
              "supervision mechanism for the node classification task. A simulated annealing\n",
              "learning strategy is then adopted to balance two learning tasks, node\n",
              "classification and the hop-aware attention coefficients, along the training\n",
              "timeline. Compared with state-of-the-art models, the experimental results\n",
              "proved the superior effectiveness of the proposed Hop-aware Supervision Graph\n",
              "Attention Networks (HopGAT) model. Especially, for the protein-protein\n",
              "interaction network, in a 40% labeled graph, the performance loss is only 3.9%,\n",
              "from 98.5% to 94.6%, compared to the fully labeled graph. Extensive experiments\n",
              "also demonstrate the effectiveness of supervised attention coefficient and\n",
              "learning strategies.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row8_col2\" class=\"data row8 col2\" ><a href=\"https://arxiv.org/abs/2004.04333\">https://arxiv.org/abs/2004.04333</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row9_col0\" class=\"data row9 col0\" >Feedback Recurrent Autoencoder for Video Compression</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row9_col1\" class=\"data row9 col1\" >Recent advances in deep generative modeling have enabled efficient modeling\n",
              "of high dimensional data distributions and opened up a new horizon for solving\n",
              "data compression problems. Specifically, autoencoder based learned image or\n",
              "video compression solutions are emerging as strong competitors to traditional\n",
              "approaches. In this work, We propose a new network architecture, based on\n",
              "common and well studied components, for learned video compression operating in\n",
              "low latency mode. Our method yields state of the art MS-SSIM/rate performance\n",
              "on the high-resolution UVG dataset, among both learned video compression\n",
              "approaches and classical video compression methods (H.265 and H.264) in the\n",
              "rate range of interest for streaming applications. Additionally, we provide an\n",
              "analysis of existing approaches through the lens of their underlying\n",
              "probabilistic graphical models. Finally, we point out issues with temporal\n",
              "consistency and color shift observed in empirical evaluation, and suggest\n",
              "directions forward to alleviate those.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row9_col2\" class=\"data row9 col2\" ><a href=\"https://arxiv.org/abs/2004.04342\">https://arxiv.org/abs/2004.04342</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row10_col0\" class=\"data row10 col0\" >Detecting Dynamic Community Structure in Functional Brain Networks  Across Individuals: A Multilayer Apporach</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row10_col1\" class=\"data row10 col1\" >We present a unified statistical framework for characterizing community\n",
              "structure of brain functional networks that captures variation across\n",
              "individuals and evolution over time. Existing methods for community detection\n",
              "focus only on single-subject analysis of dynamic networks; while recent\n",
              "extensions to multiple-subjects analysis are limited to static networks. To\n",
              "overcome these limitations, we propose a multi-subject, Markov-switching\n",
              "stochastic block model (MSS-SBM) to identify state-related changes in brain\n",
              "community organization over a group of individuals. We first formulate a\n",
              "multilayer extension of SBM to describe the time-dependent, multi-subject brain\n",
              "networks. We develop a novel procedure for fitting the multilayer SBM that\n",
              "builds on multislice modularity maximization which can uncover a common\n",
              "community partition of all layers (subjects) simultaneously. By augmenting with\n",
              "a dynamic Markov switching process, our proposed method is able to capture a\n",
              "set of distinct, recurring temporal states with respect to inter-community\n",
              "interactions over subjects and the change points between them. Simulation shows\n",
              "accurate community recovery and tracking of dynamic community regimes over\n",
              "multilayer networks by the MSS-SBM. Application to task fMRI reveals meaningful\n",
              "non-assortative brain community motifs, e.g., core-periphery structure at the\n",
              "group level, that are associated with language comprehension and motor\n",
              "functions suggesting their putative role in complex information integration.\n",
              "Our approach detected dynamic reconfiguration of modular connectivity elicited\n",
              "by varying task demands and identified unique profiles of intra and\n",
              "inter-community connectivity across different task conditions. The proposed\n",
              "multilayer network representation provides a principled way of detecting\n",
              "synchronous, dynamic modularity in brain networks across subjects.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row10_col2\" class=\"data row10 col2\" ><a href=\"https://arxiv.org/abs/2004.04362\">https://arxiv.org/abs/2004.04362</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row11_col0\" class=\"data row11 col0\" >Spectral Discovery of Jointly Smooth Features for Multimodal Data</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row11_col1\" class=\"data row11 col1\" >In this paper, we propose a spectral method for deriving functions that are\n",
              "jointly smooth on multiple observed manifolds. Our method is unsupervised and\n",
              "primarily consists of two steps. First, using kernels, we obtain a subspace\n",
              "spanning smooth functions on each manifold. Then, we apply a spectral method to\n",
              "the obtained subspaces and discover functions that are jointly smooth on all\n",
              "manifolds. We show analytically that our method is guaranteed to provide a set\n",
              "of orthogonal functions that are as jointly smooth as possible, ordered from\n",
              "the smoothest to the least smooth. In addition, we show that the proposed\n",
              "method can be efficiently extended to unseen data using the Nystr\\\"{o}m method.\n",
              "We demonstrate the proposed method on both simulated and real measured data and\n",
              "compare the results to nonlinear variants of the seminal Canonical Correlation\n",
              "Analysis (CCA). Particularly, we show superior results for sleep stage\n",
              "identification. In addition, we show how the proposed method can be leveraged\n",
              "for finding minimal realizations of parameter spaces of nonlinear dynamical\n",
              "systems.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row11_col2\" class=\"data row11 col2\" ><a href=\"https://arxiv.org/abs/2004.04386\">https://arxiv.org/abs/2004.04386</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row12_col0\" class=\"data row12 col0\" >Anomaly Detection with SDAE</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row12_col1\" class=\"data row12 col1\" >Anomaly detection is a prominent data preprocessing step in learning\n",
              "applications for correction and/or removal of faulty data. Automating this data\n",
              "type with the use of autoencoders could increase the quality of the dataset by\n",
              "isolating anomalies that were missed through manual or basic statistical\n",
              "analysis. A Simple, Deep, and Supervised Deep Autoencoder were trained and\n",
              "compared for anomaly detection over the ASHRAE building energy dataset. Given\n",
              "the restricted parameters under which the models were trained, the Deep\n",
              "Autoencoder perfoms the best, however, the Supervised Deep Autoencoder\n",
              "outperforms the other models in total anomalies detected when considerations\n",
              "for the test datasets are given.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row12_col2\" class=\"data row12 col2\" ><a href=\"https://arxiv.org/abs/2004.04391\">https://arxiv.org/abs/2004.04391</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row13_col0\" class=\"data row13 col0\" >Score-Guided Generative Adversarial Networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row13_col1\" class=\"data row13 col1\" >We propose a Generative Adversarial Network (GAN) that introduces an\n",
              "evaluator module using pre-trained networks. The proposed model, called\n",
              "score-guided GAN (ScoreGAN), is trained with an evaluation metric for GANs,\n",
              "i.e., the Inception score, as a rough guide for the training of the generator.\n",
              "By using another pre-trained network instead of the Inception network, ScoreGAN\n",
              "circumvents the overfitting of the Inception network in order that generated\n",
              "samples do not correspond to adversarial examples of the Inception network.\n",
              "Also, to prevent the overfitting, the evaluation metrics are employed only as\n",
              "an auxiliary role, while the conventional target of GANs is mainly used.\n",
              "Evaluated with the CIFAR-10 dataset, ScoreGAN demonstrated an Inception score\n",
              "of 10.36$\\pm$0.15, which corresponds to state-of-the-art performance.\n",
              "Furthermore, to generalize the effectiveness of ScoreGAN, the model was further\n",
              "evaluated with another dataset, i.e., the CIFAR-100; as a result, ScoreGAN\n",
              "outperformed the other existing methods, where the Fr\\'echet Inception Distance\n",
              "(FID) of ScoreGAN trained over the CIFAR-100 dataset was 13.98.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row13_col2\" class=\"data row13 col2\" ><a href=\"https://arxiv.org/abs/2004.04396\">https://arxiv.org/abs/2004.04396</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row14_col0\" class=\"data row14 col0\" >On Anomaly Interpretation via Shapley Values</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row14_col1\" class=\"data row14 col1\" >Anomaly localization is an essential problem as anomaly detection is. Because\n",
              "a rigorous localization requires a causal model of a target system, practically\n",
              "we often resort to a relaxed problem of anomaly interpretation, for which we\n",
              "are to obtain meaningful attribution of anomaly scores to input features. In\n",
              "this paper, we investigate the use of the Shapley value for anomaly\n",
              "interpretation. We focus on the semi-supervised anomaly detection and newly\n",
              "propose a characteristic function, on which the Shapley value is computed,\n",
              "specifically for anomaly scores. The idea of the proposed method is\n",
              "approximating the absence of some features by minimizing an anomaly score with\n",
              "regard to them. We examine the performance of the proposed method as well as\n",
              "other general approaches to computing the Shapley value in interpreting anomaly\n",
              "scores. We show the results of experiments on multiple datasets and anomaly\n",
              "detection methods, which indicate the usefulness of the Shapley-based anomaly\n",
              "interpretation toward anomaly localization.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row14_col2\" class=\"data row14 col2\" ><a href=\"https://arxiv.org/abs/2004.04464\">https://arxiv.org/abs/2004.04464</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row15_col0\" class=\"data row15 col0\" >Adversarial Latent Autoencoders</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row15_col1\" class=\"data row15 col1\" >Autoencoder networks are unsupervised approaches aiming at combining\n",
              "generative and representational properties by learning simultaneously an\n",
              "encoder-generator map. Although studied extensively, the issues of whether they\n",
              "have the same generative power of GANs, or learn disentangled representations,\n",
              "have not been fully addressed. We introduce an autoencoder that tackles these\n",
              "issues jointly, which we call Adversarial Latent Autoencoder (ALAE). It is a\n",
              "general architecture that can leverage recent improvements on GAN training\n",
              "procedures. We designed two autoencoders: one based on a MLP encoder, and\n",
              "another based on a StyleGAN generator, which we call StyleALAE. We verify the\n",
              "disentanglement properties of both architectures. We show that StyleALAE can\n",
              "not only generate 1024x1024 face images with comparable quality of StyleGAN,\n",
              "but at the same resolution can also produce face reconstructions and\n",
              "manipulations based on real images. This makes ALAE the first autoencoder able\n",
              "to compare with, and go beyond the capabilities of a generator-only type of\n",
              "architecture.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row15_col2\" class=\"data row15 col2\" ><a href=\"https://arxiv.org/abs/2004.04467\">https://arxiv.org/abs/2004.04467</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row16_col0\" class=\"data row16 col0\" >On Adversarial Examples and Stealth Attacks in Artificial Intelligence  Systems</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row16_col1\" class=\"data row16 col1\" >In this work we present a formal theoretical framework for assessing and\n",
              "analyzing two classes of malevolent action towards generic Artificial\n",
              "Intelligence (AI) systems. Our results apply to general multi-class classifiers\n",
              "that map from an input space into a decision space, including artificial neural\n",
              "networks used in deep learning applications. Two classes of attacks are\n",
              "considered. The first class involves adversarial examples and concerns the\n",
              "introduction of small perturbations of the input data that cause\n",
              "misclassification. The second class, introduced here for the first time and\n",
              "named stealth attacks, involves small perturbations to the AI system itself.\n",
              "Here the perturbed system produces whatever output is desired by the attacker\n",
              "on a specific small data set, perhaps even a single input, but performs as\n",
              "normal on a validation set (which is unknown to the attacker). We show that in\n",
              "both cases, i.e., in the case of an attack based on adversarial examples and in\n",
              "the case of a stealth attack, the dimensionality of the AI's decision-making\n",
              "space is a major contributor to the AI's susceptibility. For attacks based on\n",
              "adversarial examples, a second crucial parameter is the absence of local\n",
              "concentrations in the data probability distribution, a property known as\n",
              "Smeared Absolute Continuity. According to our findings, robustness to\n",
              "adversarial examples requires either (a) the data distributions in the AI's\n",
              "feature space to have concentrated probability density functions or (b) the\n",
              "dimensionality of the AI's decision variables to be sufficiently small. We also\n",
              "show how to construct stealth attacks on high-dimensional AI systems that are\n",
              "hard to spot unless the validation set is made exponentially large.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row16_col2\" class=\"data row16 col2\" ><a href=\"https://arxiv.org/abs/2004.04479\">https://arxiv.org/abs/2004.04479</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row17_col0\" class=\"data row17 col0\" >Learnable Subspace Clustering</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row17_col1\" class=\"data row17 col1\" >This paper studies the large-scale subspace clustering (LSSC) problem with\n",
              "million data points. Many popular subspace clustering methods cannot directly\n",
              "handle the LSSC problem although they have been considered as state-of-the-art\n",
              "methods for small-scale data points. A basic reason is that these methods often\n",
              "choose all data points as a big dictionary to build huge coding models, which\n",
              "results in a high time and space complexity. In this paper, we develop a\n",
              "learnable subspace clustering paradigm to efficiently solve the LSSC problem.\n",
              "The key idea is to learn a parametric function to partition the\n",
              "high-dimensional subspaces into their underlying low-dimensional subspaces\n",
              "instead of the expensive costs of the classical coding models. Moreover, we\n",
              "propose a unified robust predictive coding machine (RPCM) to learn the\n",
              "parametric function, which can be solved by an alternating minimization\n",
              "algorithm. In addition, we provide a bounded contraction analysis of the\n",
              "parametric function. To the best of our knowledge, this paper is the first work\n",
              "to efficiently cluster millions of data points among the subspace clustering\n",
              "methods. Experiments on million-scale datasets verify that our paradigm\n",
              "outperforms the related state-of-the-art methods in both efficiency and\n",
              "effectiveness.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row17_col2\" class=\"data row17 col2\" ><a href=\"https://arxiv.org/abs/2004.04520\">https://arxiv.org/abs/2004.04520</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row18_col0\" class=\"data row18 col0\" >k-Nearest Neighbour Classifiers -- 2nd Edition</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row18_col1\" class=\"data row18 col1\" >Perhaps the most straightforward classifier in the arsenal or machine\n",
              "learning techniques is the Nearest Neighbour Classifier -- classification is\n",
              "achieved by identifying the nearest neighbours to a query example and using\n",
              "those neighbours to determine the class of the query. This approach to\n",
              "classification is of particular importance because issues of poor run-time\n",
              "performance is not such a problem these days with the computational power that\n",
              "is available. This paper presents an overview of techniques for Nearest\n",
              "Neighbour classification focusing on; mechanisms for assessing similarity\n",
              "(distance), computational issues in identifying nearest neighbours and\n",
              "mechanisms for reducing the dimension of the data.\n",
              "This paper is the second edition of a paper previously published as a\n",
              "technical report. Sections on similarity measures for time-series, retrieval\n",
              "speed-up and intrinsic dimensionality have been added. An Appendix is included\n",
              "providing access to Python code for the key methods.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row18_col2\" class=\"data row18 col2\" ><a href=\"https://arxiv.org/abs/2004.04523\">https://arxiv.org/abs/2004.04523</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row19_col0\" class=\"data row19 col0\" >Recognizing Spatial Configurations of Objects with Graph Neural Networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row19_col1\" class=\"data row19 col1\" >Deep learning algorithms can be seen as compositions of functions acting on\n",
              "learned representations encoded as tensor-structured data. However, in most\n",
              "applications those representations are monolithic, with for instance one single\n",
              "vector encoding an entire image or sentence. In this paper, we build upon the\n",
              "recent successes of Graph Neural Networks (GNNs) to explore the use of\n",
              "graph-structured representations for learning spatial configurations. Motivated\n",
              "by the ability of humans to distinguish arrangements of shapes, we introduce\n",
              "two novel geometrical reasoning tasks, for which we provide the datasets. We\n",
              "introduce novel GNN layers and architectures to solve the tasks and show that\n",
              "graph-structured representations are necessary for good performance.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row19_col2\" class=\"data row19 col2\" ><a href=\"https://arxiv.org/abs/2004.04546\">https://arxiv.org/abs/2004.04546</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row20_col0\" class=\"data row20 col0\" >Interactions in information spread: quantification and interpretation  using stochastic block models</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row20_col1\" class=\"data row20 col1\" >In most real-world applications, it is seldom the case that a given\n",
              "observable evolves independently of its environment. In social networks, users'\n",
              "behavior results from the people they interact with, news in their feed, or\n",
              "trending topics. In natural language, the meaning of phrases emerges from the\n",
              "combination of words. In general medicine, a diagnosis is established on the\n",
              "basis of the interaction of symptoms. Here, we propose a new model, the\n",
              "Interactive Mixed Membership Stochastic Block Model (IMMSBM), which\n",
              "investigates the role of interactions between entities (hashtags, words, memes,\n",
              "etc.) and quantifies their importance within the aforementioned corpora. We\n",
              "find that interactions play an important role in those corpora. In inference\n",
              "tasks, taking them into account leads to average relative changes with respect\n",
              "to non-interactive models of up to 150\\% in the probability of an outcome.\n",
              "Furthermore, their role greatly improves the predictive power of the model. Our\n",
              "findings suggest that neglecting interactions when modeling real-world\n",
              "phenomena might lead to incorrect conclusions being drawn.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row20_col2\" class=\"data row20 col2\" ><a href=\"https://arxiv.org/abs/2004.04552\">https://arxiv.org/abs/2004.04552</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row21_col0\" class=\"data row21 col0\" >Learning Bayesian Networks that enable full propagation of evidence</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row21_col1\" class=\"data row21 col1\" >This paper builds on recent developments in Bayesian network (BN) structure\n",
              "learning under the controversial assumption that the input variables are\n",
              "dependent. This assumption is geared towards real-world datasets that\n",
              "incorporate variables which are assumed to be dependent. It aims to address the\n",
              "problem of learning multiple disjoint subgraphs which do not enable full\n",
              "propagation of evidence. A novel hybrid structure learning algorithm is\n",
              "presented in this paper for this purpose, called SaiyanH. The results show that\n",
              "the algorithm discovers satisfactorily accurate connected DAGs in cases where\n",
              "all other algorithms produce multiple disjoint subgraphs for dependent\n",
              "variables. This problem is highly prevalent in cases where the sample size of\n",
              "the input data is low with respect to the dimensionality of the model, which is\n",
              "often the case when working with real data. Based on six case studies, five\n",
              "different sample sizes, three different evaluation metrics, and other\n",
              "state-of-the-art or well-established constraint-based, score-based and hybrid\n",
              "learning algorithms, the results rank SaiyanH 4th out of 13 algorithms for\n",
              "overall performance.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row21_col2\" class=\"data row21 col2\" ><a href=\"https://arxiv.org/abs/2004.04571\">https://arxiv.org/abs/2004.04571</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row22_col0\" class=\"data row22 col0\" >Backprojection for Training Feedforward Neural Networks in the Input and  Feature Spaces</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row22_col1\" class=\"data row22 col1\" >After the tremendous development of neural networks trained by\n",
              "backpropagation, it is a good time to develop other algorithms for training\n",
              "neural networks to gain more insights into networks. In this paper, we propose\n",
              "a new algorithm for training feedforward neural networks which is fairly faster\n",
              "than backpropagation. This method is based on projection and reconstruction\n",
              "where, at every layer, the projected data and reconstructed labels are forced\n",
              "to be similar and the weights are tuned accordingly layer by layer. The\n",
              "proposed algorithm can be used for both input and feature spaces, named as\n",
              "backprojection and kernel backprojection, respectively. This algorithm gives an\n",
              "insight to networks with a projection-based perspective. The experiments on\n",
              "synthetic datasets show the effectiveness of the proposed method.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row22_col2\" class=\"data row22 col2\" ><a href=\"https://arxiv.org/abs/2004.04573\">https://arxiv.org/abs/2004.04573</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row23_col0\" class=\"data row23 col0\" >The Importance of Good Starting Solutions in the Minimum Sum of Squares  Clustering Problem</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row23_col1\" class=\"data row23 col1\" >The clustering problem has many applications in Machine Learning, Operations\n",
              "Research, and Statistics. We propose three algorithms to create starting\n",
              "solutions for improvement algorithms for this problem. We test the algorithms\n",
              "on 72 instances that were investigated in the literature. Forty eight of them\n",
              "are relatively easy to solve and we found the best known solution many times\n",
              "for all of them. Twenty four medium and large size instances are more\n",
              "challenging. We found five new best known solutions and matched the best known\n",
              "solution for 18 of the remaining 19 instances.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row23_col2\" class=\"data row23 col2\" ><a href=\"https://arxiv.org/abs/2004.04593\">https://arxiv.org/abs/2004.04593</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row24_col0\" class=\"data row24 col0\" >Deep Reinforcement Learning (DRL): Another Perspective for Unsupervised  Wireless Localization</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row24_col1\" class=\"data row24 col1\" >Location is key to spatialize internet-of-things (IoT) data. However, it is\n",
              "challenging to use low-cost IoT devices for robust unsupervised localization\n",
              "(i.e., localization without training data that have known location labels).\n",
              "Thus, this paper proposes a deep reinforcement learning (DRL) based\n",
              "unsupervised wireless-localization method. The main contributions are as\n",
              "follows. (1) This paper proposes an approach to model a continuous\n",
              "wireless-localization process as a Markov decision process (MDP) and process it\n",
              "within a DRL framework. (2) To alleviate the challenge of obtaining rewards\n",
              "when using unlabeled data (e.g., daily-life crowdsourced data), this paper\n",
              "presents a reward-setting mechanism, which extracts robust landmark data from\n",
              "unlabeled wireless received signal strengths (RSS). (3) To ease requirements\n",
              "for model re-training when using DRL for localization, this paper uses RSS\n",
              "measurements together with agent location to construct DRL inputs. The proposed\n",
              "method was tested by using field testing data from multiple Bluetooth 5 smart\n",
              "ear tags in a pasture. Meanwhile, the experimental verification process\n",
              "reflected the advantages and challenges for using DRL in wireless localization.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row24_col2\" class=\"data row24 col2\" ><a href=\"https://arxiv.org/abs/2004.04618\">https://arxiv.org/abs/2004.04618</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row25_col0\" class=\"data row25 col0\" >Nonnegativity-Enforced Gaussian Process Regression</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row25_col1\" class=\"data row25 col1\" >Gaussian Process (GP) regression is a flexible non-parametric approach to\n",
              "approximate complex models. In many cases, these models correspond to processes\n",
              "with bounded physical properties. Standard GP regression typically results in a\n",
              "proxy model which is unbounded for all temporal or spacial points, and thus\n",
              "leaves the possibility of taking on infeasible values. We propose an approach\n",
              "to enforce the physical constraints in a probabilistic way under the GP\n",
              "regression framework. In addition, this new approach reduces the variance in\n",
              "the resulting GP model.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row25_col2\" class=\"data row25 col2\" ><a href=\"https://arxiv.org/abs/2004.04632\">https://arxiv.org/abs/2004.04632</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row26_col0\" class=\"data row26 col0\" >Graph Highway Networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row26_col1\" class=\"data row26 col1\" >Graph Convolution Networks (GCN) are widely used in learning graph\n",
              "representations due to their effectiveness and efficiency. However, they suffer\n",
              "from the notorious over-smoothing problem, in which the learned representations\n",
              "of densely connected nodes converge to alike vectors when many (>3) graph\n",
              "convolutional layers are stacked. In this paper, we argue that\n",
              "there-normalization trick used in GCN leads to overly homogeneous information\n",
              "propagation, which is the source of over-smoothing. To address this problem, we\n",
              "propose Graph Highway Networks(GHNet) which utilize gating units to\n",
              "automatically balance the trade-off between homogeneity and heterogeneity in\n",
              "the GCN learning process. The gating units serve as direct highways to maintain\n",
              "heterogeneous information from the node itself after feature propagation. This\n",
              "design enables GHNet to achieve much larger receptive fields per node without\n",
              "over-smoothing and thus access to more of the graph connectivity information.\n",
              "Experimental results on benchmark datasets demonstrate the superior performance\n",
              "of GHNet over GCN and related models.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row26_col2\" class=\"data row26 col2\" ><a href=\"https://arxiv.org/abs/2004.04635\">https://arxiv.org/abs/2004.04635</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row27_col0\" class=\"data row27 col0\" >CNN2Gate: Toward Designing a General Framework for Implementation of  Convolutional Neural Networks on FPGA</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row27_col1\" class=\"data row27 col1\" >Convolutional Neural Networks (CNNs) have a major impact on our society\n",
              "because of the numerous services they provide. On the other hand, they require\n",
              "considerable computing power. To satisfy these requirements, it is possible to\n",
              "use graphic processing units (GPUs). However, high power consumption and\n",
              "limited external IOs constrain their usability and suitability in industrial\n",
              "and mission-critical scenarios. Recently, the number of researches that utilize\n",
              "FPGAs to implement CNNs are increasing rapidly. This is due to the lower power\n",
              "consumption and easy reconfigurability offered by these platforms. Because of\n",
              "the research efforts put into topics such as architecture, synthesis and\n",
              "optimization, some new challenges are arising to integrate such hardware\n",
              "solutions to high-level machine learning software libraries. This paper\n",
              "introduces an integrated framework (CNN2Gate) that supports compilation of a\n",
              "CNN model for an FPGA target. CNN2Gate exploits the OpenCL\\textsuperscript{TM}\n",
              "synthesis workflow for FPGAs offered by commercial vendors. CNN2Gate is capable\n",
              "of parsing CNN models from several popular high-level machine learning\n",
              "libraries such as Keras, Pytorch, Caffe2 etc. CNN2Gate extracts computation\n",
              "flow of layers, in addition to weights and biases and applies a \"given\"\n",
              "fixed-point quantization. Furthermore, it writes this information in the proper\n",
              "format for OpenCL synthesis tools that are then used to build and run the\n",
              "project on FPGA. CNN2Gate performs design-space exploration using a\n",
              "reinforcement learning agent and fits the design on different FPGAs with\n",
              "limited logic resources automatically. This paper reports results of automatic\n",
              "synthesis and design-space exploration of AlexNet and VGG-16 on various Intel\n",
              "FPGA platforms. CNN2Gate achieves a latency of 205 ms for VGG-16 and 18 ms for\n",
              "AlexNet on the FPGA.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row27_col2\" class=\"data row27 col2\" ><a href=\"https://arxiv.org/abs/2004.04641\">https://arxiv.org/abs/2004.04641</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row28_col0\" class=\"data row28 col0\" >Data Dieting in GAN Training</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row28_col1\" class=\"data row28 col1\" >We investigate training Generative Adversarial Networks, GANs, with less\n",
              "data. Subsets of the training dataset can express empirical sample diversity\n",
              "while reducing training resource requirements, e.g. time and memory. We ask how\n",
              "much data reduction impacts generator performance and gauge the additive value\n",
              "of generator ensembles. In addition to considering stand-alone GAN training and\n",
              "ensembles of generator models, we also consider reduced data training on an\n",
              "evolutionary GAN training framework named Redux-Lipizzaner. Redux-Lipizzaner\n",
              "makes GAN training more robust and accurate by exploiting overlapping\n",
              "neighborhood-based training on a spatial 2D grid. We conduct empirical\n",
              "experiments on Redux-Lipizzaner using the MNIST and CelebA data sets.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row28_col2\" class=\"data row28 col2\" ><a href=\"https://arxiv.org/abs/2004.04642\">https://arxiv.org/abs/2004.04642</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row29_col0\" class=\"data row29 col0\" >On the Ethics of Building AI in a Responsible Manner</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row29_col1\" class=\"data row29 col1\" >The AI-alignment problem arises when there is a discrepancy between the goals\n",
              "that a human designer specifies to an AI learner and a potential catastrophic\n",
              "outcome that does not reflect what the human designer really wants. We argue\n",
              "that a formalism of AI alignment that does not distinguish between strategic\n",
              "and agnostic misalignments is not useful, as it deems all technology as\n",
              "un-safe. We propose a definition of a strategic-AI-alignment and prove that\n",
              "most machine learning algorithms that are being used in practice today do not\n",
              "suffer from the strategic-AI-alignment problem. However, without being careful,\n",
              "today's technology might lead to strategic misalignment.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row29_col2\" class=\"data row29 col2\" ><a href=\"https://arxiv.org/abs/2004.04644\">https://arxiv.org/abs/2004.04644</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row30_col0\" class=\"data row30 col0\" >Query-Focused EHR Summarization to Aid Imaging Diagnosis</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row30_col1\" class=\"data row30 col1\" >Electronic Health Records (EHRs) provide vital contextual information to\n",
              "radiologists and other physicians when making a diagnosis. Unfortunately,\n",
              "because a given patient's record may contain hundreds of notes and reports,\n",
              "identifying relevant information within these in the short time typically\n",
              "allotted to a case is very difficult. We propose and evaluate models that\n",
              "extract relevant text snippets from patient records to provide a rough case\n",
              "summary intended to aid physicians considering one or more diagnoses. This is\n",
              "hard because direct supervision (i.e., physician annotations of snippets\n",
              "relevant to specific diagnoses in medical records) is prohibitively expensive\n",
              "to collect at scale. We propose a distantly supervised strategy in which we use\n",
              "groups of International Classification of Diseases (ICD) codes observed in\n",
              "'future' records as noisy proxies for 'downstream' diagnoses. Using this we\n",
              "train a transformer-based neural model to perform extractive summarization\n",
              "conditioned on potential diagnoses. This model defines an attention mechanism\n",
              "that is conditioned on potential diagnoses (queries) provided by the diagnosing\n",
              "physician. We train (via distant supervision) and evaluate variants of this\n",
              "model on EHR data from a local hospital and MIMIC-III (the latter to facilitate\n",
              "reproducibility). Evaluations performed by radiologists demonstrate that these\n",
              "distantly supervised models yield better extractive summaries than do\n",
              "unsupervised approaches. Such models may aid diagnosis by identifying sentences\n",
              "in past patient reports that are clinically relevant to a potential diagnoses.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row30_col2\" class=\"data row30 col2\" ><a href=\"https://arxiv.org/abs/2004.04645\">https://arxiv.org/abs/2004.04645</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row31_col0\" class=\"data row31 col0\" >Structure-preserving neural networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row31_col1\" class=\"data row31 col1\" >We develop a method to learn physical systems from data that employs\n",
              "feedforward neural networks and whose predictions comply with the first and\n",
              "second principles of thermodynamics. The method employs a minimum amount of\n",
              "data by enforcing the metriplectic structure of dissipative Hamiltonian systems\n",
              "in the form of the so-called General Equation for the Non-Equilibrium\n",
              "Reversible-Irreversible Coupling, GENERIC [M. Grmela and H.C Oettinger (1997).\n",
              "Dynamics and thermodynamics of complex fluids. I. Development of a general\n",
              "formalism. Phys. Rev. E. 56 (6): 6620-6632]. The method does not need to\n",
              "enforce any kind of balance equation, and thus no previous knowledge on the\n",
              "nature of the system is needed. Conservation of energy and dissipation of\n",
              "entropy in the prediction of previously unseen situations arise as a natural\n",
              "by-product of the structure of the method. Examples of the performance of the\n",
              "method are shown that include conservative as well as dissipative systems,\n",
              "discrete as well as continuous ones.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row31_col2\" class=\"data row31 col2\" ><a href=\"https://arxiv.org/abs/2004.04653\">https://arxiv.org/abs/2004.04653</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row32_col0\" class=\"data row32 col0\" >Residual Shuffle-Exchange Networks for Fast Processing of Long Sequences</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row32_col1\" class=\"data row32 col1\" >Attention is a commonly used mechanism in sequence processing, but it is of\n",
              "O(n^2) complexity which prevents its application to long sequences. The\n",
              "recently introduced Neural Shuffle-Exchange network offers a\n",
              "computation-efficient alternative, enabling the modelling of long-range\n",
              "dependencies in O(n log n) time. The model, however, is quite complex,\n",
              "involving a sophisticated gating mechanism derived from Gated Recurrent Unit.\n",
              "In this paper, we present a simple and lightweight variant of the\n",
              "Shuffle-Exchange network, which is based on a residual network employing GELU\n",
              "and Layer Normalization. The proposed architecture not only scales to longer\n",
              "sequences but also converges faster and provides better accuracy. It surpasses\n",
              "Shuffle-Exchange network on the LAMBADA language modelling task and achieves\n",
              "state-of-the-art performance on the MusicNet dataset for music transcription\n",
              "while using significantly fewer parameters. We show how to combine\n",
              "Shuffle-Exchange network with convolutional layers establishing it as a useful\n",
              "building block in long sequence processing applications.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row32_col2\" class=\"data row32 col2\" ><a href=\"https://arxiv.org/abs/2004.04662\">https://arxiv.org/abs/2004.04662</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row33_col0\" class=\"data row33 col0\" >Geomstats: A Python Package for Riemannian Geometry in Machine Learning</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row33_col1\" class=\"data row33 col1\" >We introduce Geomstats, an open-source Python toolbox for computations and\n",
              "statistics on nonlinear manifolds, such as hyperbolic spaces, spaces of\n",
              "symmetric positive definite matrices, Lie groups of transformations, and many\n",
              "more. We provide object-oriented and extensively unit-tested implementations.\n",
              "Among others, manifolds come equipped with families of Riemannian metrics, with\n",
              "associated exponential and logarithmic maps, geodesics and parallel transport.\n",
              "Statistics and learning algorithms provide methods for estimation, clustering\n",
              "and dimension reduction on manifolds. All associated operations are vectorized\n",
              "for batch computation and provide support for different execution backends,\n",
              "namely NumPy, PyTorch and TensorFlow, enabling GPU acceleration. This paper\n",
              "presents the package, compares it with related libraries and provides relevant\n",
              "code examples. We show that Geomstats provides reliable building blocks to\n",
              "foster research in differential geometry and statistics, and to democratize the\n",
              "use of Riemannian geometry in machine learning applications. The source code is\n",
              "freely available under the MIT license at \\url{geomstats.ai}.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row33_col2\" class=\"data row33 col2\" ><a href=\"https://arxiv.org/abs/2004.04667\">https://arxiv.org/abs/2004.04667</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row34_col0\" class=\"data row34 col0\" >Fisher Discriminant Triplet and Contrastive Losses for Training Siamese  Networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row34_col1\" class=\"data row34 col1\" >Siamese neural network is a very powerful architecture for both feature\n",
              "extraction and metric learning. It usually consists of several networks that\n",
              "share weights. The Siamese concept is topology-agnostic and can use any neural\n",
              "network as its backbone. The two most popular loss functions for training these\n",
              "networks are the triplet and contrastive loss functions. In this paper, we\n",
              "propose two novel loss functions, named Fisher Discriminant Triplet (FDT) and\n",
              "Fisher Discriminant Contrastive (FDC). The former uses anchor-neighbor-distant\n",
              "triplets while the latter utilizes pairs of anchor-neighbor and anchor-distant\n",
              "samples. The FDT and FDC loss functions are designed based on the statistical\n",
              "formulation of the Fisher Discriminant Analysis (FDA), which is a linear\n",
              "subspace learning method. Our experiments on the MNIST and two challenging and\n",
              "publicly available histopathology datasets show the effectiveness of the\n",
              "proposed loss functions.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row34_col2\" class=\"data row34 col2\" ><a href=\"https://arxiv.org/abs/2004.04674\">https://arxiv.org/abs/2004.04674</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row35_col0\" class=\"data row35 col0\" >A Short Note on Analyzing Sequence Complexity in Trajectory Prediction  Benchmarks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row35_col1\" class=\"data row35 col1\" >The analysis and quantification of sequence complexity is an open problem\n",
              "frequently encountered when defining trajectory prediction benchmarks. In order\n",
              "to enable a more informative assembly of a data basis, an approach for\n",
              "determining a dataset representation in terms of a small set of distinguishable\n",
              "prototypical sub-sequences is proposed. The approach employs a sequence\n",
              "alignment followed by a learning vector quantization (LVQ) stage. A first proof\n",
              "of concept on synthetically generated and real-world datasets shows the\n",
              "viability of the approach.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row35_col2\" class=\"data row35 col2\" ><a href=\"https://arxiv.org/abs/2004.04677\">https://arxiv.org/abs/2004.04677</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row36_col0\" class=\"data row36 col0\" >Machine Learning in Artificial Intelligence: Towards a Common  Understanding</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row36_col1\" class=\"data row36 col1\" >The application of \"machine learning\" and \"artificial intelligence\" has\n",
              "become popular within the last decade. Both terms are frequently used in\n",
              "science and media, sometimes interchangeably, sometimes with different\n",
              "meanings. In this work, we aim to clarify the relationship between these terms\n",
              "and, in particular, to specify the contribution of machine learning to\n",
              "artificial intelligence. We review relevant literature and present a conceptual\n",
              "framework which clarifies the role of machine learning to build (artificial)\n",
              "intelligent agents. Hence, we seek to provide more terminological clarity and a\n",
              "starting point for (interdisciplinary) discussions and future research.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row36_col2\" class=\"data row36 col2\" ><a href=\"https://arxiv.org/abs/2004.04686\">https://arxiv.org/abs/2004.04686</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row37_col0\" class=\"data row37 col0\" >Orthogonal Over-Parameterized Training</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row37_col1\" class=\"data row37 col1\" >The inductive bias of a neural network is largely determined by the\n",
              "architecture and the training algorithm. To achieve good generalization, how to\n",
              "effectively train a neural network is even more important than designing the\n",
              "architecture. We propose a novel orthogonal over-parameterized training (OPT)\n",
              "framework that can provably minimize the hyperspherical energy which\n",
              "characterizes the diversity of neurons on a hypersphere. By constantly\n",
              "maintaining the minimum hyperspherical energy during training, OPT can greatly\n",
              "improve the network generalization. Specifically, OPT fixes the randomly\n",
              "initialized weights of the neurons and learns an orthogonal transformation that\n",
              "applies to these neurons. We propose multiple ways to learn such an orthogonal\n",
              "transformation, including unrolling orthogonalization algorithms, applying\n",
              "orthogonal parameterization, and designing orthogonality-preserving gradient\n",
              "update. Interestingly, OPT reveals that learning a proper coordinate system for\n",
              "neurons is crucial to generalization and may be more important than learning a\n",
              "specific relative position of neurons. We further provide theoretical insights\n",
              "of why OPT yields better generalization. Extensive experiments validate the\n",
              "superiority of OPT.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row37_col2\" class=\"data row37 col2\" ><a href=\"https://arxiv.org/abs/2004.04690\">https://arxiv.org/abs/2004.04690</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row38_col0\" class=\"data row38 col0\" >Heuristics for Link Prediction in Multiplex Networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row38_col1\" class=\"data row38 col1\" >Link prediction, or the inference of future or missing connections between\n",
              "entities, is a well-studied problem in network analysis. A multitude of\n",
              "heuristics exist for link prediction in ordinary networks with a single type of\n",
              "connection. However, link prediction in multiplex networks, or networks with\n",
              "multiple types of connections, is not a well understood problem. We propose a\n",
              "novel general framework and three families of heuristics for multiplex network\n",
              "link prediction that are simple, interpretable, and take advantage of the rich\n",
              "connection type correlation structure that exists in many real world networks.\n",
              "We further derive a theoretical threshold for determining when to use a\n",
              "different connection type based on the number of links that overlap with an\n",
              "Erdos-Renyi random graph. Through experiments with simulated and real world\n",
              "scientific collaboration, transportation and global trade networks, we\n",
              "demonstrate that the proposed heuristics show increased performance with the\n",
              "richness of connection type correlation structure and significantly outperform\n",
              "their baseline heuristics for ordinary networks with a single connection type.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row38_col2\" class=\"data row38 col2\" ><a href=\"https://arxiv.org/abs/2004.04704\">https://arxiv.org/abs/2004.04704</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row39_col0\" class=\"data row39 col0\" >Prune2Edge: A Multi-Phase Pruning Pipelines to Deep Ensemble Learning in  IIoT</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row39_col1\" class=\"data row39 col1\" >Most recently, with the proliferation of IoT devices, computational nodes in\n",
              "manufacturing systems IIoT(Industrial-Internet-of-things) and the lunch of 5G\n",
              "networks, there will be millions of connected devices generating a massive\n",
              "amount of data. In such an environment, the controlling systems need to be\n",
              "intelligent enough to deal with a vast amount of data to detect defects in a\n",
              "real-time process. Driven by such a need, artificial intelligence models such\n",
              "as deep learning have to be deployed into IIoT systems. However, learning and\n",
              "using deep learning models are computationally expensive, so an IoT device with\n",
              "limited computational power could not run such models. To tackle this issue,\n",
              "edge intelligence had emerged as a new paradigm towards running Artificial\n",
              "Intelligence models on edge devices. Although a considerable amount of studies\n",
              "have been proposed in this area, the research is still in the early stages. In\n",
              "this paper, we propose a novel edge-based multi-phase pruning pipelines to\n",
              "ensemble learning on IIoT devices. In the first phase, we generate a diverse\n",
              "ensemble of pruned models, then we apply integer quantisation, next we prune\n",
              "the generated ensemble using a clustering-based technique. Finally, we choose\n",
              "the best representative from each generated cluster to be deployed to a\n",
              "distributed IoT environment. On CIFAR-100 and CIFAR-10, our proposed approach\n",
              "was able to outperform the predictability levels of a baseline model (up to\n",
              "7%), more importantly, the generated learners have small sizes (up to 90%\n",
              "reduction in the model size) that minimise the required computational\n",
              "capabilities to make an inference on the resource-constraint devices.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row39_col2\" class=\"data row39 col2\" ><a href=\"https://arxiv.org/abs/2004.04710\">https://arxiv.org/abs/2004.04710</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row40_col0\" class=\"data row40 col0\" >Dithered backprop: A sparse and quantized backpropagation algorithm for  more efficient deep neural network training</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row40_col1\" class=\"data row40 col1\" >Deep Neural Networks are successful but highly computationally expensive\n",
              "learning systems. One of the main sources of time and energy drains is the well\n",
              "known backpropagation (backprop) algorithm, which roughly accounts for 2/3 of\n",
              "the computational complexity of training. In this work we propose a method for\n",
              "reducing the computational cost of backprop, which we named dithered backprop.\n",
              "It consists in applying a stochastic quantization scheme to intermediate\n",
              "results of the method. The particular quantisation scheme, called\n",
              "non-subtractive dither (NSD), induces sparsity which can be exploited by\n",
              "computing efficient sparse matrix multiplications. Experiments on popular image\n",
              "classification tasks show that it induces 92% sparsity on average across a wide\n",
              "set of models at no or negligible accuracy drop in comparison to\n",
              "state-of-the-art approaches, thus significantly reducing the computational\n",
              "complexity of the backward pass. Moreover, we show that our method is fully\n",
              "compatible to state-of-the-art training methods that reduce the bit-precision\n",
              "of training down to 8-bits, as such being able to further reduce the\n",
              "computational requirements. Finally we discuss and show potential benefits of\n",
              "applying dithered backprop in a distributed training setting, where both\n",
              "communication as well as compute efficiency may increase simultaneously with\n",
              "the number of participant nodes.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row40_col2\" class=\"data row40 col2\" ><a href=\"https://arxiv.org/abs/2004.04729\">https://arxiv.org/abs/2004.04729</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row41_col0\" class=\"data row41 col0\" >MetaSleepLearner: Fast Adaptation of Bio-signals-Based Sleep Stage  Classifier to New Individual Subject Using Meta-Learning</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row41_col1\" class=\"data row41 col1\" >Objective: Identifying bio-signals based-sleep stages requires time-consuming\n",
              "and tedious labor of skilled clinicians. Deep learning approaches have been\n",
              "introduced in order to challenge the automatic sleep stage classification\n",
              "conundrum. However, disadvantages can be posed in replacing the clinicians with\n",
              "the automatic system. Thus, we aim to develop a framework, capable of assisting\n",
              "the clinicians and lessening the workload. Methods: We proposed the transfer\n",
              "learning framework entitled MetaSleepLearner, using a Model Agnostic\n",
              "Meta-Learning (MAML), in order to transfer the acquired sleep staging knowledge\n",
              "from a large dataset to new individual subject. The capability of MAML was\n",
              "elicited for this task by allowing clinicians to label for a few samples and\n",
              "let the rest be handled by the system. Layer-wise Relevance Propagation (LRP)\n",
              "was also applied to understand the learning course of our approach. Results: In\n",
              "all acquired datasets, in comparison to the conventional approach,\n",
              "MetaSleepLearner achieved a range of 6.15 % to 12.12 % improvement with\n",
              "statistical difference in the mean of both approaches. The illustration of the\n",
              "model interpretation after the adaptation to each subject also confirmed that\n",
              "the performance was directed towards reasonable learning. Conclusion:\n",
              "MetaSleepLearner outperformed the conventional approach as a result from the\n",
              "fine-tuning using the recordings of both healthy subjects and patients.\n",
              "Significance: This is the first paper that investigated a non-conventional\n",
              "pre-training method, MAML, in this task, resulting in a framework for\n",
              "human-machine collaboration in sleep stage classification, easing the burden of\n",
              "the clinicians in labelling the sleep stages through only several epochs rather\n",
              "than an entire recording.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row41_col2\" class=\"data row41 col2\" ><a href=\"https://arxiv.org/abs/2004.04157\">https://arxiv.org/abs/2004.04157</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row42_col0\" class=\"data row42 col0\" >Inpainting via Generative Adversarial Networks for CMB data analysis</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row42_col1\" class=\"data row42 col1\" >In this work, we propose a new method to inpaint the CMB signal in regions\n",
              "masked out following a point source extraction process. We adopt a modified\n",
              "Generative Adversarial Network (GAN) and compare different combinations of\n",
              "internal (hyper-)parameters and training strategies. We study the performance\n",
              "using a suitable $\\mathcal{C}_r$ variable in order to estimate the performance\n",
              "regarding the CMB power spectrum recovery. We consider a test set where one\n",
              "point source is masked out in each sky patch with a 1.83 $\\times$ 1.83 squared\n",
              "degree extension, which, in our gridding, corresponds to 64 $\\times$ 64 pixels.\n",
              "The GAN is optimized for estimating performance on Planck 2018 total intensity\n",
              "simulations. The training makes the GAN effective in reconstructing a masking\n",
              "corresponding to about 1500 pixels with $1\\%$ error down to angular scales\n",
              "corresponding to about 5 arcminutes.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row42_col2\" class=\"data row42 col2\" ><a href=\"https://arxiv.org/abs/2004.04177\">https://arxiv.org/abs/2004.04177</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row43_col0\" class=\"data row43 col0\" >Leveraging 2D Data to Learn Textured 3D Mesh Generation</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row43_col1\" class=\"data row43 col1\" >Numerous methods have been proposed for probabilistic generative modelling of\n",
              "3D objects. However, none of these is able to produce textured objects, which\n",
              "renders them of limited use for practical tasks. In this work, we present the\n",
              "first generative model of textured 3D meshes. Training such a model would\n",
              "traditionally require a large dataset of textured meshes, but unfortunately,\n",
              "existing datasets of meshes lack detailed textures. We instead propose a new\n",
              "training methodology that allows learning from collections of 2D images without\n",
              "any 3D information. To do so, we train our model to explain a distribution of\n",
              "images by modelling each image as a 3D foreground object placed in front of a\n",
              "2D background. Thus, it learns to generate meshes that when rendered, produce\n",
              "images similar to those in its training set.\n",
              "A well-known problem when generating meshes with deep networks is the\n",
              "emergence of self-intersections, which are problematic for many use-cases. As a\n",
              "second contribution we therefore introduce a new generation process for 3D\n",
              "meshes that guarantees no self-intersections arise, based on the physical\n",
              "intuition that faces should push one another out of the way as they move.\n",
              "We conduct extensive experiments on our approach, reporting quantitative and\n",
              "qualitative results on both synthetic data and natural images. These show our\n",
              "method successfully learns to generate plausible and diverse textured 3D\n",
              "samples for five challenging object classes.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row43_col2\" class=\"data row43 col2\" ><a href=\"https://arxiv.org/abs/2004.04180\">https://arxiv.org/abs/2004.04180</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row44_col0\" class=\"data row44 col0\" >The GeoLifeCLEF 2020 Dataset</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row44_col1\" class=\"data row44 col1\" >Understanding the geographic distribution of species is a key concern in\n",
              "conservation. By pairing species occurrences with environmental features,\n",
              "researchers can model the relationship between an environment and the species\n",
              "which may be found there. To facilitate research in this area, we present the\n",
              "GeoLifeCLEF 2020 dataset, which consists of 1.9 million species observations\n",
              "paired with high-resolution remote sensing imagery, land cover data, and\n",
              "altitude, in addition to traditional low-resolution climate and soil variables.\n",
              "We also discuss the GeoLifeCLEF 2020 competition, which aims to use this\n",
              "dataset to advance the state-of-the-art in location-based species\n",
              "recommendation.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row44_col2\" class=\"data row44 col2\" ><a href=\"https://arxiv.org/abs/2004.04192\">https://arxiv.org/abs/2004.04192</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row45_col0\" class=\"data row45 col0\" >Bayesian Interpolants as Explanations for Neural Inferences</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row45_col1\" class=\"data row45 col1\" >The notion of Craig interpolant, used as a form of explanation in automated\n",
              "reasoning, is adapted from logical inference to statistical inference and used\n",
              "to explain inferences made by neural networks. The method produces explanations\n",
              "that are at the same time concise, understandable and precise.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row45_col2\" class=\"data row45 col2\" ><a href=\"https://arxiv.org/abs/2004.04198\">https://arxiv.org/abs/2004.04198</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row46_col0\" class=\"data row46 col0\" >A single image deep learning approach to restoration of corrupted remote  sensing products</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row46_col1\" class=\"data row46 col1\" >Remote sensing images are used for a variety of analyses, from agricultural\n",
              "monitoring, to disaster relief, to resource planning, among others. The images\n",
              "can be corrupted due to a number of reasons, including instrument errors and\n",
              "natural obstacles such as clouds. We present here a novel approach for\n",
              "reconstruction of missing information in such cases using only the corrupted\n",
              "image as the input. The Deep Image Prior methodology eliminates the need for a\n",
              "pre-trained network or an image database. It is shown that the approach easily\n",
              "beats the performance of traditional single-image methods.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row46_col2\" class=\"data row46 col2\" ><a href=\"https://arxiv.org/abs/2004.04209\">https://arxiv.org/abs/2004.04209</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row47_col0\" class=\"data row47 col0\" >Variable Rate Video Compression using a Hybrid Recurrent Convolutional  Learning Framework</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row47_col1\" class=\"data row47 col1\" >In recent years, neural network-based image compression techniques have been\n",
              "able to outperform traditional codecs and have opened the gates for the\n",
              "development of learning-based video codecs. However, to take advantage of the\n",
              "high temporal correlation in videos, more sophisticated architectures need to\n",
              "be employed. This paper presents PredEncoder, a hybrid video compression\n",
              "framework based on the concept of predictive auto-encoding that models the\n",
              "temporal correlations between consecutive video frames using a prediction\n",
              "network which is then combined with a progressive encoder network to exploit\n",
              "the spatial redundancies. A variable-rate block encoding scheme has been\n",
              "proposed in the paper that leads to remarkably high quality to bit-rate ratios.\n",
              "By joint training and fine-tuning of this hybrid architecture, PredEncoder has\n",
              "been able to gain significant improvement over the MPEG-4 codec and has\n",
              "achieved bit-rate savings over the H.264 codec in the low to medium bit-rate\n",
              "range for HD videos and comparable results over most bit-rates for non-HD\n",
              "videos. This paper serves to demonstrate how neural architectures can be\n",
              "leveraged to perform at par with the highly optimized traditional methodologies\n",
              "in the video compression domain.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row47_col2\" class=\"data row47 col2\" ><a href=\"https://arxiv.org/abs/2004.04244\">https://arxiv.org/abs/2004.04244</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row48_col0\" class=\"data row48 col0\" >An Improved Cutting Plane Method for Convex Optimization, Convex-Concave  Games and its Applications</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row48_col1\" class=\"data row48 col1\" >Given a separation oracle for a convex set $K \\subset \\mathbb{R}^n$ that is\n",
              "contained in a box of radius $R$, the goal is to either compute a point in $K$\n",
              "or prove that $K$ does not contain a ball of radius $\\epsilon$. We propose a\n",
              "new cutting plane algorithm that uses an optimal $O(n \\log (\\kappa))$\n",
              "evaluations of the oracle and an additional $O(n^2)$ time per evaluation, where\n",
              "$\\kappa = nR/\\epsilon$.\n",
              "$\\bullet$ This improves upon Vaidya's $O( \\text{SO} \\cdot n \\log (\\kappa) +\n",
              "n^{\\omega+1} \\log (\\kappa))$ time algorithm [Vaidya, FOCS 1989a] in terms of\n",
              "polynomial dependence on $n$, where $\\omega < 2.373$ is the exponent of matrix\n",
              "multiplication and $\\text{SO}$ is the time for oracle evaluation.\n",
              "$\\bullet$ This improves upon Lee-Sidford-Wong's $O( \\text{SO} \\cdot n \\log\n",
              "(\\kappa) + n^3 \\log^{O(1)} (\\kappa))$ time algorithm [Lee, Sidford and Wong,\n",
              "FOCS 2015] in terms of dependence on $\\kappa$.\n",
              "For many important applications in economics, $\\kappa = \\Omega(\\exp(n))$ and\n",
              "this leads to a significant difference between $\\log(\\kappa)$ and\n",
              "$\\mathrm{poly}(\\log (\\kappa))$. We also provide evidence that the $n^2$ time\n",
              "per evaluation cannot be improved and thus our running time is optimal.\n",
              "A bottleneck of previous cutting plane methods is to compute leverage scores,\n",
              "a measure of the relative importance of past constraints. Our result is\n",
              "achieved by a novel multi-layered data structure for leverage score\n",
              "maintenance, which is a sophisticated combination of diverse techniques such as\n",
              "random projection, batched low-rank update, inverse maintenance, polynomial\n",
              "interpolation, and fast rectangular matrix multiplication. Interestingly, our\n",
              "method requires a combination of different fast rectangular matrix\n",
              "multiplication algorithms.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row48_col2\" class=\"data row48 col2\" ><a href=\"https://arxiv.org/abs/2004.04250\">https://arxiv.org/abs/2004.04250</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row49_col0\" class=\"data row49 col0\" >nPINNs: nonlocal Physics-Informed Neural Networks for a parametrized  nonlocal universal Laplacian operator. Algorithms and Applications</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row49_col1\" class=\"data row49 col1\" >Physics-informed neural networks (PINNs) are effective in solving inverse\n",
              "problems based on differential and integral equations with sparse, noisy,\n",
              "unstructured, and multi-fidelity data. PINNs incorporate all available\n",
              "information into a loss function, thus recasting the original problem into an\n",
              "optimization problem. In this paper, we extend PINNs to parameter and function\n",
              "inference for integral equations such as nonlocal Poisson and nonlocal\n",
              "turbulence models, and we refer to them as nonlocal PINNs (nPINNs). The\n",
              "contribution of the paper is three-fold. First, we propose a unified nonlocal\n",
              "operator, which converges to the classical Laplacian as one of the operator\n",
              "parameters, the nonlocal interaction radius $\\delta$ goes to zero, and to the\n",
              "fractional Laplacian as $\\delta$ goes to infinity. This universal operator\n",
              "forms a super-set of classical Laplacian and fractional Laplacian operators\n",
              "and, thus, has the potential to fit a broad spectrum of data sets. We provide\n",
              "theoretical convergence rates with respect to $\\delta$ and verify them via\n",
              "numerical experiments. Second, we use nPINNs to estimate the two parameters,\n",
              "$\\delta$ and $\\alpha$. The strong non-convexity of the loss function yielding\n",
              "multiple (good) local minima reveals the occurrence of the operator mimicking\n",
              "phenomenon: different pairs of estimated parameters could produce multiple\n",
              "solutions of comparable accuracy. Third, we propose another nonlocal operator\n",
              "with spatially variable order $\\alpha(y)$, which is more suitable for modeling\n",
              "turbulent Couette flow. Our results show that nPINNs can jointly infer this\n",
              "function as well as $\\delta$. Also, these parameters exhibit a universal\n",
              "behavior with respect to the Reynolds number, a finding that contributes to our\n",
              "understanding of nonlocal interactions in wall-bounded turbulence.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row49_col2\" class=\"data row49 col2\" ><a href=\"https://arxiv.org/abs/2004.04276\">https://arxiv.org/abs/2004.04276</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row50_col0\" class=\"data row50 col0\" >The Adaptive Stress Testing Formulation</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row50_col1\" class=\"data row50 col1\" >Validation is a key challenge in the search for safe autonomy. Simulations\n",
              "are often either too simple to provide robust validation, or too complex to\n",
              "tractably compute. Therefore, approximate validation methods are needed to\n",
              "tractably find failures without unsafe simplifications. This paper presents the\n",
              "theory behind one such black-box approach: adaptive stress testing (AST). We\n",
              "also provide three examples of validation problems formulated to work with AST.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row50_col2\" class=\"data row50 col2\" ><a href=\"https://arxiv.org/abs/2004.04293\">https://arxiv.org/abs/2004.04293</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row51_col0\" class=\"data row51 col0\" >Physics-enhanced machine learning for virtual fluorescence microscopy</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row51_col1\" class=\"data row51 col1\" >This paper introduces a supervised deep-learning network that jointly\n",
              "optimizes the physical setup of an optical microscope to infer fluorescence\n",
              "image information. Specifically, we design a bright-field microscope's\n",
              "illumination module to maximize the performance for inference of fluorescent\n",
              "cellular features from bright-field imagery. We take advantage of the wide\n",
              "degree of flexibility available in illuminating a sample to optimize for\n",
              "programmable patterns of light from a customized LED array, which produce\n",
              "better task-specific performance than standard lighting techniques. We achieve\n",
              "illumination pattern optimization by including a physical model of image\n",
              "formation within the initial layers of a deep convolutional network. Our\n",
              "optimized illumination patterns result in up to a 45% performance improvement\n",
              "as compared to standard imaging methods, and we additionally explore how the\n",
              "optimized patterns vary as a function of inference task. This work demonstrates\n",
              "the importance of optimizing the process of image capture via programmable\n",
              "optical elements to improve automated analysis, and offers new physical\n",
              "insights into expected performance gains of recent fluorescence image inference\n",
              "work.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row51_col2\" class=\"data row51 col2\" ><a href=\"https://arxiv.org/abs/2004.04306\">https://arxiv.org/abs/2004.04306</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row52_col0\" class=\"data row52 col0\" >Client Selection and Bandwidth Allocation in Wireless Federated Learning  Networks: A Long-Term Perspective</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row52_col1\" class=\"data row52 col1\" >This paper studies federated learning (FL) in a classic wireless network,\n",
              "where learning clients share a common wireless link to a coordinating server to\n",
              "perform federated model training using their local data. In such wireless\n",
              "federated learning networks (WFLNs), optimizing the learning performance\n",
              "depends crucially on how clients are selected and how bandwidth is allocated\n",
              "among the selected clients in every learning round, as both radio and client\n",
              "energy resources are limited. While existing works have made some attempts to\n",
              "allocate the limited wireless resources to optimize FL, they focus on the\n",
              "problem in individual learning rounds, overlooking an inherent yet critical\n",
              "feature of federated learning. This paper brings a new long-term perspective to\n",
              "resource allocation in WFLNs, realizing that learning rounds are not only\n",
              "temporally interdependent but also have varying significance towards the final\n",
              "learning outcome. To this end, we first design data-driven experiments to show\n",
              "that different temporal client selection patterns lead to considerably\n",
              "different learning performance. With the obtained insights, we formulate a\n",
              "stochastic optimization problem for joint client selection and bandwidth\n",
              "allocation under long-term client energy constraints, and develop a new\n",
              "algorithm that utilizes only currently available wireless channel information\n",
              "but can achieve long-term performance guarantee. Further experiments show that\n",
              "our algorithm results in the desired temporal client selection pattern, is\n",
              "adaptive to changing network environments and far outperforms benchmarks that\n",
              "ignore the long-term effect of FL.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row52_col2\" class=\"data row52 col2\" ><a href=\"https://arxiv.org/abs/2004.04314\">https://arxiv.org/abs/2004.04314</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row53_col0\" class=\"data row53 col0\" >Pruning and Sparsemax Methods for Hierarchical Attention Networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row53_col1\" class=\"data row53 col1\" >This paper introduces and evaluates two novel Hierarchical Attention Network\n",
              "models [Yang et al., 2016] - i) Hierarchical Pruned Attention Networks, which\n",
              "remove the irrelevant words and sentences from the classification process in\n",
              "order to reduce potential noise in the document classification accuracy and ii)\n",
              "Hierarchical Sparsemax Attention Networks, which replace the Softmax function\n",
              "used in the attention mechanism with the Sparsemax [Martins and Astudillo,\n",
              "2016], capable of better handling importance distributions where a lot of words\n",
              "or sentences have very low probabilities. Our empirical evaluation on the IMDB\n",
              "Review for sentiment analysis datasets shows both approaches to be able to\n",
              "match the results obtained by the current state-of-the-art (without, however,\n",
              "any significant benefits). All our source code is made available\n",
              "athttps://github.com/jmribeiro/dsl-project.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row53_col2\" class=\"data row53 col2\" ><a href=\"https://arxiv.org/abs/2004.04343\">https://arxiv.org/abs/2004.04343</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row54_col0\" class=\"data row54 col0\" >Calibrating Structured Output Predictors for Natural Language Processing</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row54_col1\" class=\"data row54 col1\" >We address the problem of calibrating prediction confidence for output\n",
              "entities of interest in natural language processing (NLP) applications. It is\n",
              "important that NLP applications such as named entity recognition and question\n",
              "answering produce calibrated confidence scores for their predictions,\n",
              "especially if the system is to be deployed in a safety-critical domain such as\n",
              "healthcare. However, the output space of such structured prediction models is\n",
              "often too large to adapt binary or multi-class calibration methods directly. In\n",
              "this study, we propose a general calibration scheme for output entities of\n",
              "interest in neural-network based structured prediction models. Our proposed\n",
              "method can be used with any binary class calibration scheme and a neural\n",
              "network model. Additionally, we show that our calibration method can also be\n",
              "used as an uncertainty-aware, entity-specific decoding step to improve the\n",
              "performance of the underlying model at no additional training cost or data\n",
              "requirements. We show that our method outperforms current calibration\n",
              "techniques for named-entity-recognition, part-of-speech and question answering.\n",
              "We also improve our model's performance from our decoding step across several\n",
              "tasks and benchmark datasets. Our method improves the calibration and model\n",
              "performance on out-of-domain test scenarios as well.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row54_col2\" class=\"data row54 col2\" ><a href=\"https://arxiv.org/abs/2004.04361\">https://arxiv.org/abs/2004.04361</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row55_col0\" class=\"data row55 col0\" >A Review of Vibration-Based Damage Detection in Civil Structures: From  Traditional Methods to Machine Learning and Deep Learning Applications</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row55_col1\" class=\"data row55 col1\" >Monitoring structural damage is extremely important for sustaining and\n",
              "preserving the service life of civil structures. While successful monitoring\n",
              "provides resolute and staunch information on the health, serviceability,\n",
              "integrity and safety of structures; maintaining continuous performance of a\n",
              "structure depends highly on monitoring the occurrence, formation and\n",
              "propagation of damage. Damage may accumulate on structures due to different\n",
              "environmental and human-induced factors. Numerous monitoring and detection\n",
              "approaches have been developed to provide practical means for early warning\n",
              "against structural damage or any type of anomaly. Considerable effort has been\n",
              "put into vibration-based methods, which utilize the vibration response of the\n",
              "monitored structure to assess its condition and identify structural damage.\n",
              "Meanwhile, with emerging computing power and sensing technology in the last\n",
              "decade, Machine Learning (ML) and especially Deep Learning (DL) algorithms have\n",
              "become more feasible and extensively used in vibration-based structural damage\n",
              "detection with elegant performance and often with rigorous accuracy. While\n",
              "there have been multiple review studies published on vibration-based structural\n",
              "damage detection, there has not been a study where the transition from\n",
              "traditional methods to ML and DL methods are described and discussed. This\n",
              "paper aims to fulfill this gap by presenting the highlights of the traditional\n",
              "methods and provide a comprehensive review of the most recent applications of\n",
              "ML and DL algorithms utilized for vibration-based structural damage detection\n",
              "in civil structures.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row55_col2\" class=\"data row55 col2\" ><a href=\"https://arxiv.org/abs/2004.04373\">https://arxiv.org/abs/2004.04373</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row56_col0\" class=\"data row56 col0\" >Towards Inheritable Models for Open-Set Domain Adaptation</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row56_col1\" class=\"data row56 col1\" >There has been a tremendous progress in Domain Adaptation (DA) for visual\n",
              "recognition tasks. Particularly, open-set DA has gained considerable attention\n",
              "wherein the target domain contains additional unseen categories. Existing\n",
              "open-set DA approaches demand access to a labeled source dataset along with\n",
              "unlabeled target instances. However, this reliance on co-existing source and\n",
              "target data is highly impractical in scenarios where data-sharing is restricted\n",
              "due to its proprietary nature or privacy concerns. Addressing this, we\n",
              "introduce a practical DA paradigm where a source-trained model is used to\n",
              "facilitate adaptation in the absence of the source dataset in future. To this\n",
              "end, we formalize knowledge inheritability as a novel concept and propose a\n",
              "simple yet effective solution to realize inheritable models suitable for the\n",
              "above practical paradigm. Further, we present an objective way to quantify\n",
              "inheritability to enable the selection of the most suitable source model for a\n",
              "given target domain, even in the absence of the source data. We provide\n",
              "theoretical insights followed by a thorough empirical evaluation demonstrating\n",
              "state-of-the-art open-set domain adaptation performance.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row56_col2\" class=\"data row56 col2\" ><a href=\"https://arxiv.org/abs/2004.04388\">https://arxiv.org/abs/2004.04388</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row57_col0\" class=\"data row57 col0\" >Universal Source-Free Domain Adaptation</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row57_col1\" class=\"data row57 col1\" >There is a strong incentive to develop versatile learning techniques that can\n",
              "transfer the knowledge of class-separability from a labeled source domain to an\n",
              "unlabeled target domain in the presence of a domain-shift. Existing domain\n",
              "adaptation (DA) approaches are not equipped for practical DA scenarios as a\n",
              "result of their reliance on the knowledge of source-target label-set\n",
              "relationship (e.g. Closed-set, Open-set or Partial DA). Furthermore, almost all\n",
              "prior unsupervised DA works require coexistence of source and target samples\n",
              "even during deployment, making them unsuitable for real-time adaptation. Devoid\n",
              "of such impractical assumptions, we propose a novel two-stage learning process.\n",
              "1) In the Procurement stage, we aim to equip the model for future source-free\n",
              "deployment, assuming no prior knowledge of the upcoming category-gap and\n",
              "domain-shift. To achieve this, we enhance the model's ability to reject\n",
              "out-of-source distribution samples by leveraging the available source data, in\n",
              "a novel generative classifier framework. 2) In the Deployment stage, the goal\n",
              "is to design a unified adaptation algorithm capable of operating across a wide\n",
              "range of category-gaps, with no access to the previously seen source samples.\n",
              "To this end, in contrast to the usage of complex adversarial training regimes,\n",
              "we define a simple yet effective source-free adaptation objective by utilizing\n",
              "a novel instance-level weighting mechanism, named as Source Similarity Metric\n",
              "(SSM). A thorough evaluation shows the practical usability of the proposed\n",
              "learning framework with superior DA performance even over state-of-the-art\n",
              "source-dependent approaches.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row57_col2\" class=\"data row57 col2\" ><a href=\"https://arxiv.org/abs/2004.04393\">https://arxiv.org/abs/2004.04393</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row58_col0\" class=\"data row58 col0\" >Hierarchical Group Sparse Regularization for Deep Convolutional Neural  Networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row58_col1\" class=\"data row58 col1\" >In a deep neural network (DNN), the number of the parameters is usually huge\n",
              "to get high learning performances. For that reason, it costs a lot of memory\n",
              "and substantial computational resources, and also causes overfitting. It is\n",
              "known that some parameters are redundant and can be removed from the network\n",
              "without decreasing performance. Many sparse regularization criteria have been\n",
              "proposed to solve this problem. In a convolutional neural network (CNN), group\n",
              "sparse regularizations are often used to remove unnecessary subsets of the\n",
              "weights, such as filters or channels. When we apply a group sparse\n",
              "regularization for the weights connected to a neuron as a group, each\n",
              "convolution filter is not treated as a target group in the regularization. In\n",
              "this paper, we introduce the concept of hierarchical grouping to solve this\n",
              "problem, and we propose several hierarchical group sparse regularization\n",
              "criteria for CNNs. Our proposed the hierarchical group sparse regularization\n",
              "can treat the weight for the input-neuron or the output-neuron as a group and\n",
              "convolutional filter as a group in the same group to prune the unnecessary\n",
              "subsets of weights. As a result, we can prune the weights more adequately\n",
              "depending on the structure of the network and the number of channels keeping\n",
              "high performance. In the experiment, we investigate the effectiveness of the\n",
              "proposed sparse regularizations through intensive comparison experiments on\n",
              "public datasets with several network architectures. Code is available on\n",
              "GitHub: \"https://github.com/K-Mitsuno/hierarchical-group-sparse-regularization\"\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row58_col2\" class=\"data row58 col2\" ><a href=\"https://arxiv.org/abs/2004.04394\">https://arxiv.org/abs/2004.04394</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row59_col0\" class=\"data row59 col0\" >Online Meta-Learning for Multi-Source and Semi-Supervised Domain  Adaptation</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row59_col1\" class=\"data row59 col1\" >Domain adaptation (DA) is the topical problem of adapting models from\n",
              "labelled source datasets so that they perform well on target datasets where\n",
              "only unlabelled or partially labelled data is available. Many methods have been\n",
              "proposed to address this problem through different ways to minimise the domain\n",
              "shift between source and target datasets. In this paper we take an orthogonal\n",
              "perspective and propose a framework to further enhance performance by\n",
              "meta-learning the initial conditions of existing DA algorithms. This is\n",
              "challenging compared to the more widely considered setting of few-shot\n",
              "meta-learning, due to the length of the computation graph involved. Therefore\n",
              "we propose an online shortest-path meta-learning framework that is both\n",
              "computationally tractable and practically effective for improving DA\n",
              "performance. We present variants for both multi-source unsupervised domain\n",
              "adaptation (MSDA), and semi-supervised domain adaptation (SSDA). Importantly,\n",
              "our approach is agnostic to the base adaptation algorithm, and can be applied\n",
              "to improve many techniques. Experimentally, we demonstrate improvements on\n",
              "classic (DANN) and recent (MCD and MME) techniques for MSDA and SSDA, and\n",
              "ultimately achieve state of the art results on several DA benchmarks including\n",
              "the largest scale DomainNet.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row59_col2\" class=\"data row59 col2\" ><a href=\"https://arxiv.org/abs/2004.04398\">https://arxiv.org/abs/2004.04398</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row60\" class=\"row_heading level0 row60\" >60</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row60_col0\" class=\"data row60 col0\" >Reinforced Anytime Bottom Up Rule Learning for Knowledge Graph  Completion</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row60_col1\" class=\"data row60 col1\" >Most of todays work on knowledge graph completion is concerned with\n",
              "sub-symbolic approaches that focus on the concept of embedding a given graph in\n",
              "a low dimensional vector space. Against this trend, we propose an approach\n",
              "called AnyBURL that is rooted in the symbolic space. Its core algorithm is\n",
              "based on sampling paths, which are generalized into Horn rules. Previously\n",
              "published results show that the prediction quality of AnyBURL is on the same\n",
              "level as current state of the art with the additional benefit of offering an\n",
              "explanation for the predicted fact. In this paper, we are concerned with two\n",
              "extensions of AnyBURL. Firstly, we change AnyBURLs interpretation of rules from\n",
              "$\\Theta$-subsumption into $\\Theta$-subsumption under Object Identity. Secondly,\n",
              "we introduce reinforcement learning to better guide the sampling process. We\n",
              "found out that reinforcement learning helps finding more valuable rules earlier\n",
              "in the search process. We measure the impact of both extensions and compare the\n",
              "resulting approach with current state of the art approaches. Our results show\n",
              "that AnyBURL outperforms most sub-symbolic methods.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row60_col2\" class=\"data row60 col2\" ><a href=\"https://arxiv.org/abs/2004.04412\">https://arxiv.org/abs/2004.04412</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row61\" class=\"row_heading level0 row61\" >61</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row61_col0\" class=\"data row61 col0\" >On optimal transformer depth for low-resource language translation</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row61_col1\" class=\"data row61 col1\" >Transformers have shown great promise as an approach to Neural Machine\n",
              "Translation (NMT) for low-resource languages. However, at the same time,\n",
              "transformer models remain difficult to optimize and require careful tuning of\n",
              "hyper-parameters to be useful in this setting. Many NMT toolkits come with a\n",
              "set of default hyper-parameters, which researchers and practitioners often\n",
              "adopt for the sake of convenience and avoiding tuning. These configurations,\n",
              "however, have been optimized for large-scale machine translation data sets with\n",
              "several millions of parallel sentences for European languages like English and\n",
              "French. In this work, we find that the current trend in the field to use very\n",
              "large models is detrimental for low-resource languages, since it makes training\n",
              "more difficult and hurts overall performance, confirming previous observations.\n",
              "We see our work as complementary to the Masakhane project (\"Masakhane\" means\n",
              "\"We Build Together\" in isiZulu.) In this spirit, low-resource NMT systems are\n",
              "now being built by the community who needs them the most. However, many in the\n",
              "community still have very limited access to the type of computational resources\n",
              "required for building extremely large models promoted by industrial research.\n",
              "Therefore, by showing that transformer models perform well (and often best) at\n",
              "low-to-moderate depth, we hope to convince fellow researchers to devote less\n",
              "computational resources, as well as time, to exploring overly large models\n",
              "during the development of these systems.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row61_col2\" class=\"data row61 col2\" ><a href=\"https://arxiv.org/abs/2004.04418\">https://arxiv.org/abs/2004.04418</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row62\" class=\"row_heading level0 row62\" >62</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row62_col0\" class=\"data row62 col0\" >Towards Exploiting Implicit Human Feedback for Improving RDF2vec  Embeddings</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row62_col1\" class=\"data row62 col1\" >RDF2vec is a technique for creating vector space embeddings from an RDF\n",
              "knowledge graph, i.e., representing each entity in the graph as a vector. It\n",
              "first creates sequences of nodes by performing random walks on the graph. In a\n",
              "second step, those sequences are processed by the word2vec algorithm for\n",
              "creating the actual embeddings. In this paper, we explore the use of external\n",
              "edge weights for guiding the random walks. As edge weights, transition\n",
              "probabilities between pages in Wikipedia are used as a proxy for the human\n",
              "feedback for the importance of an edge. We show that in some scenarios, RDF2vec\n",
              "utilizing those transition probabilities can outperform both RDF2vec based on\n",
              "random walks as well as the usage of graph internal edge weights.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row62_col2\" class=\"data row62 col2\" ><a href=\"https://arxiv.org/abs/2004.04423\">https://arxiv.org/abs/2004.04423</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row63\" class=\"row_heading level0 row63\" >63</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row63_col0\" class=\"data row63 col0\" >Automatic detection of acute ischemic stroke using non-contrast computed  tomography and two-stage deep learning model</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row63_col1\" class=\"data row63 col1\" >Background and Purpose: We aimed to develop and evaluate an automatic acute\n",
              "ischemic stroke-related (AIS) detection system involving a two-stage deep\n",
              "learning model.\n",
              "Methods: We included 238 cases from two different institutions. AIS-related\n",
              "findings were annotated on each of the 238 sets of head CT images by referring\n",
              "to head magnetic resonance imaging (MRI) images in which an MRI examination was\n",
              "performed within 24 h following the CT scan. These 238 annotated cases were\n",
              "divided into a training set including 189 cases and test set including 49\n",
              "cases. Subsequently, a two-stage deep learning detection model was constructed\n",
              "from the training set using the You Only Look Once v3 model and Visual Geometry\n",
              "Group 16 classification model. Then, the two-stage model performed the AIS\n",
              "detection process in the test set. To assess the detection model's results, a\n",
              "board-certified radiologist also evaluated the test set head CT images with and\n",
              "without the aid of the detection model. The sensitivity of AIS detection and\n",
              "number of false positives were calculated for the evaluation of the test set\n",
              "detection results. The sensitivity of the radiologist with and without the\n",
              "software detection results was compared using the McNemar test. A p-value of\n",
              "less than 0.05 was considered statistically significant.\n",
              "Results: For the two-stage model and radiologist without and with the use of\n",
              "the software results, the sensitivity was 37.3%, 33.3%, and 41.3%,\n",
              "respectively, and the number of false positives per one case was 1.265, 0.327,\n",
              "and 0.388, respectively. On using the two-stage detection model's results, the\n",
              "board-certified radiologist's detection sensitivity significantly improved\n",
              "(p-value = 0.0313).\n",
              "Conclusions: Our detection system involving the two-stage deep learning model\n",
              "significantly improved the radiologist's sensitivity in AIS detection.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row63_col2\" class=\"data row63 col2\" ><a href=\"https://arxiv.org/abs/2004.04432\">https://arxiv.org/abs/2004.04432</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row64\" class=\"row_heading level0 row64\" >64</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row64_col0\" class=\"data row64 col0\" >DeepSEE: Deep Disentangled Semantic Explorative Extreme Super-Resolution</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row64_col1\" class=\"data row64 col1\" >Super-resolution (SR) is by definition ill-posed. There are infinitely many\n",
              "plausible high-resolution variants for a given low-resolution natural image.\n",
              "This is why example-based SR methods study upscaling factors up to 4x (or up to\n",
              "8x for face hallucination). Most of the current literature aims at a single\n",
              "deterministic solution of either high reconstruction fidelity or\n",
              "photo-realistic perceptual quality. In this work, we propose a novel framework,\n",
              "DeepSEE, for Deep disentangled Semantic Explorative Extreme super-resolution.\n",
              "To the best of our knowledge, DeepSEE is the first method to leverage semantic\n",
              "maps for explorative super-resolution. In particular, it provides control of\n",
              "the semantic regions, their disentangled appearance and it allows a broad range\n",
              "of image manipulations. We validate DeepSEE for up to 32x magnification and\n",
              "exploration of the space of super-resolution.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row64_col2\" class=\"data row64 col2\" ><a href=\"https://arxiv.org/abs/2004.04433\">https://arxiv.org/abs/2004.04433</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row65\" class=\"row_heading level0 row65\" >65</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row65_col0\" class=\"data row65 col0\" >Risk-Aware High-level Decisions for Automated Driving at Occluded  Intersections with Reinforcement Learning</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row65_col1\" class=\"data row65 col1\" >Reinforcement learning is nowadays a popular framework for solving different\n",
              "decision making problems in automated driving. However, there are still some\n",
              "remaining crucial challenges that need to be addressed for providing more\n",
              "reliable policies. In this paper, we propose a generic risk-aware DQN approach\n",
              "in order to learn high level actions for driving through unsignalized occluded\n",
              "intersections. The proposed state representation provides lane based\n",
              "information which allows to be used for multi-lane scenarios. Moreover, we\n",
              "propose a risk based reward function which punishes risky situations instead of\n",
              "only collision failures. Such rewarding approach helps to incorporate risk\n",
              "prediction into our deep Q network and learn more reliable policies which are\n",
              "safer in challenging situations. The efficiency of the proposed approach is\n",
              "compared with a DQN learned with conventional collision based rewarding scheme\n",
              "and also with a rule-based intersection navigation policy. Evaluation results\n",
              "show that the proposed approach outperforms both of these methods. It provides\n",
              "safer actions than collision-aware DQN approach and is less overcautious than\n",
              "the rule-based policy.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row65_col2\" class=\"data row65 col2\" ><a href=\"https://arxiv.org/abs/2004.04450\">https://arxiv.org/abs/2004.04450</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row66\" class=\"row_heading level0 row66\" >66</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row66_col0\" class=\"data row66 col0\" >TensorProjection Layer: A Tensor-Based Dimensionality Reduction Method  in CNN</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row66_col1\" class=\"data row66 col1\" >In this paper, we propose a dimensionality reduction method applied to\n",
              "tensor-structured data as a hidden layer (we call it TensorProjection Layer) in\n",
              "a convolutional neural network. Our proposed method transforms input tensors\n",
              "into ones with a smaller dimension by projection. The directions of projection\n",
              "are viewed as training parameters associated with our proposed layer and\n",
              "trained via a supervised learning criterion such as minimization of the\n",
              "cross-entropy loss function. We discuss the gradients of the loss function with\n",
              "respect to the parameters associated with our proposed layer. We also implement\n",
              "simple numerical experiments to evaluate the performance of the\n",
              "TensorProjection Layer.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row66_col2\" class=\"data row66 col2\" ><a href=\"https://arxiv.org/abs/2004.04454\">https://arxiv.org/abs/2004.04454</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row67\" class=\"row_heading level0 row67\" >67</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row67_col0\" class=\"data row67 col0\" >Fast frequency discrimination and phoneme recognition using a biomimetic  membrane coupled to a neural network</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row67_col1\" class=\"data row67 col1\" >In the human ear, the basilar membrane plays a central role in sound\n",
              "recognition. When excited by sound, this membrane responds with a\n",
              "frequency-dependent displacement pattern that is detected and identified by the\n",
              "auditory hair cells combined with the human neural system. Inspired by this\n",
              "structure, we designed and fabricated an artificial membrane that produces a\n",
              "spatial displacement pattern in response to an audible signal, which we used to\n",
              "train a convolutional neural network (CNN). When trained with single frequency\n",
              "tones, this system can unambiguously distinguish tones closely spaced in\n",
              "frequency. When instead trained to recognize spoken vowels, this system\n",
              "outperforms existing methods for phoneme recognition, including the discrete\n",
              "Fourier transform (DFT), zoom FFT and chirp z-transform, especially when tested\n",
              "in short time windows. This sound recognition scheme therefore promises\n",
              "significant benefits in fast and accurate sound identification compared to\n",
              "existing methods.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row67_col2\" class=\"data row67 col2\" ><a href=\"https://arxiv.org/abs/2004.04459\">https://arxiv.org/abs/2004.04459</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row68\" class=\"row_heading level0 row68\" >68</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row68_col0\" class=\"data row68 col0\" >LightConvPoint: convolution for points</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row68_col1\" class=\"data row68 col1\" >Recent state-of-the-art methods for point cloud semantic segmentation are\n",
              "based on convolution defined for point clouds. In this paper, we propose a\n",
              "formulation of the convolution for point cloud directly designed from the\n",
              "discrete convolution in image processing. The resulting formulation underlines\n",
              "the separation between the discrete kernel space and the geometric space where\n",
              "the points lies. The link between the two space is done by a change space\n",
              "matrix $\\mathbf{A}$ which distributes the input features on the convolution\n",
              "kernel. Several existing methods fall under this formulation. We show that the\n",
              "matrix $\\mathbf{A}$ can be easily estimated with neural networks. Finally, we\n",
              "show competitive results on several semantic segmentation benchmarks while\n",
              "being efficient both in computation time and memory.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row68_col2\" class=\"data row68 col2\" ><a href=\"https://arxiv.org/abs/2004.04462\">https://arxiv.org/abs/2004.04462</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row69\" class=\"row_heading level0 row69\" >69</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row69_col0\" class=\"data row69 col0\" >Multi-Granularity Canonical Appearance Pooling for Remote Sensing Scene  Classification</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row69_col1\" class=\"data row69 col1\" >Recognising remote sensing scene images remains challenging due to large\n",
              "visual-semantic discrepancies. These mainly arise due to the lack of detailed\n",
              "annotations that can be employed to align pixel-level representations with\n",
              "high-level semantic labels. As the tagging process is labour-intensive and\n",
              "subjective, we hereby propose a novel Multi-Granularity Canonical Appearance\n",
              "Pooling (MG-CAP) to automatically capture the latent ontological structure of\n",
              "remote sensing datasets. We design a granular framework that allows\n",
              "progressively cropping the input image to learn multi-grained features. For\n",
              "each specific granularity, we discover the canonical appearance from a set of\n",
              "pre-defined transformations and learn the corresponding CNN features through a\n",
              "maxout-based Siamese style architecture. Then, we replace the standard CNN\n",
              "features with Gaussian covariance matrices and adopt the proper matrix\n",
              "normalisations for improving the discriminative power of features. Besides, we\n",
              "provide a stable solution for training the eigenvalue-decomposition function\n",
              "(EIG) in a GPU and demonstrate the corresponding back-propagation using matrix\n",
              "calculus. Extensive experiments have shown that our framework can achieve\n",
              "promising results in public remote sensing scene datasets.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row69_col2\" class=\"data row69 col2\" ><a href=\"https://arxiv.org/abs/2004.04491\">https://arxiv.org/abs/2004.04491</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row70\" class=\"row_heading level0 row70\" >70</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row70_col0\" class=\"data row70 col0\" >Sequential Neural Rendering with Transformer</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row70_col1\" class=\"data row70 col1\" >This paper address the problem of novel view synthesis by means of neural\n",
              "rendering, where we are interested in predicting the novel view at an arbitrary\n",
              "camera pose based on a given set of input images from other viewpoints. Using\n",
              "the known query pose and input poses, we create an ordered set of observations\n",
              "that leads to the target view. Thus, the problem of single novel view synthesis\n",
              "is reformulated as a sequential view prediction task. In this paper, the\n",
              "proposed Transformer-based Generative Query Network (T-GQN) extends the\n",
              "neural-rendering methods by adding two new concepts. First, we use multi-view\n",
              "attention learning between context images to obtain multiple implicit scene\n",
              "representations. Second, we introduce a sequential rendering decoder to predict\n",
              "an image sequence, including the target view, based on the learned\n",
              "representations. We evaluate our model on various challenging synthetic\n",
              "datasets and demonstrate that our model can give consistent predictions and\n",
              "achieve faster training convergence than the former architectures.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row70_col2\" class=\"data row70 col2\" ><a href=\"https://arxiv.org/abs/2004.04548\">https://arxiv.org/abs/2004.04548</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row71\" class=\"row_heading level0 row71\" >71</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row71_col0\" class=\"data row71 col0\" >Mirror Descent Algorithms for Minimizing Interacting Free Energy</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row71_col1\" class=\"data row71 col1\" >This note considers the problem of minimizing interacting free energy.\n",
              "Motivated by the mirror descent algorithm, for a given interacting free energy,\n",
              "we propose a descent dynamics with a novel metric that takes into consideration\n",
              "the reference measure and the interacting term. This metric naturally suggests\n",
              "a monotone reparameterization of the probability measure. By discretizing the\n",
              "reparameterized descent dynamics with the explicit Euler method, we arrive at a\n",
              "new mirror-descent-type algorithm for minimizing interacting free energy.\n",
              "Numerical results are included to demonstrate the efficiency of the proposed\n",
              "algorithms.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row71_col2\" class=\"data row71 col2\" ><a href=\"https://arxiv.org/abs/2004.04555\">https://arxiv.org/abs/2004.04555</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row72\" class=\"row_heading level0 row72\" >72</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row72_col0\" class=\"data row72 col0\" >ARCH: Animatable Reconstruction of Clothed Humans</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row72_col1\" class=\"data row72 col1\" >In this paper, we propose ARCH (Animatable Reconstruction of Clothed Humans),\n",
              "a novel end-to-end framework for accurate reconstruction of animation-ready 3D\n",
              "clothed humans from a monocular image. Existing approaches to digitize 3D\n",
              "humans struggle to handle pose variations and recover details. Also, they do\n",
              "not produce models that are animation ready. In contrast, ARCH is a learned\n",
              "pose-aware model that produces detailed 3D rigged full-body human avatars from\n",
              "a single unconstrained RGB image. A Semantic Space and a Semantic Deformation\n",
              "Field are created using a parametric 3D body estimator. They allow the\n",
              "transformation of 2D/3D clothed humans into a canonical space, reducing\n",
              "ambiguities in geometry caused by pose variations and occlusions in training\n",
              "data. Detailed surface geometry and appearance are learned using an implicit\n",
              "function representation with spatial local features. Furthermore, we propose\n",
              "additional per-pixel supervision on the 3D reconstruction using opacity-aware\n",
              "differentiable rendering. Our experiments indicate that ARCH increases the\n",
              "fidelity of the reconstructed humans. We obtain more than 50% lower\n",
              "reconstruction errors for standard metrics compared to state-of-the-art methods\n",
              "on public datasets. We also show numerous qualitative examples of animated,\n",
              "high-quality reconstructed avatars unseen in the literature so far.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row72_col2\" class=\"data row72 col2\" ><a href=\"https://arxiv.org/abs/2004.04572\">https://arxiv.org/abs/2004.04572</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row73\" class=\"row_heading level0 row73\" >73</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row73_col0\" class=\"data row73 col0\" >Model-based actor-critic: GAN + DRL (actor-critic) => AGI</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row73_col1\" class=\"data row73 col1\" >Our effort is toward unifying GAN and DRL algorithms into a unifying AI model\n",
              "(AGI or general-purpose AI or artificial general intelligence which has\n",
              "general-purpose applications to: (A) offline learning (of stored data) like GAN\n",
              "in (un/semi-/fully-)SL setting such as big data analytics (mining) and\n",
              "visualization; (B) online learning (of real or simulated devices) like DRL in\n",
              "RL setting (with/out environment reward) such as (real or simulated) robotics\n",
              "and control; Our core proposal is adding an (generative/predictive) environment\n",
              "model to the actor-critic (model-free) architecture which results in a\n",
              "model-based actor-critic architecture with temporal-differencing (TD) error and\n",
              "an episodic memory. The proposed AI model is similar to (model-free) DDPG and\n",
              "therefore it's called model-based DDPG. To evaluate it, we compare it with\n",
              "(model-free) DDPG by applying them both to a variety (wide range) of\n",
              "independent simulated robotic and control task environments in OpenAI Gym and\n",
              "Unity Agents. Our initial limited experiments show that DRL and GAN in\n",
              "model-based actor-critic results in an incremental goal-driven intellignce\n",
              "required to solve each task with similar performance to (model-free) DDPG. Our\n",
              "future focus is to investigate the proposed AI model potential to: (A) unify\n",
              "DRL field inside AI by producing competitive performance compared to the best\n",
              "of model-based (PlaNet) and model-free (D4PG) approaches; (B) bridge the gap\n",
              "between AI and robotics communities by solving the important problem of reward\n",
              "engineering with learning the reward function by demonstration;\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row73_col2\" class=\"data row73 col2\" ><a href=\"https://arxiv.org/abs/2004.04574\">https://arxiv.org/abs/2004.04574</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row74\" class=\"row_heading level0 row74\" >74</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row74_col0\" class=\"data row74 col0\" >DeepCOVIDExplainer: Explainable COVID-19 Predictions Based on Chest  X-ray Images</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row74_col1\" class=\"data row74 col1\" >Amid the coronavirus disease(COVID-19) pandemic, humanity experiences a rapid\n",
              "increase in infection numbers across the world. Challenge hospitals are faced\n",
              "with, in the fight against the virus, is the effective screening of incoming\n",
              "patients. One methodology is the assessment of chest radiography(CXR) images,\n",
              "which usually requires expert radiologists' knowledge. In this paper, we\n",
              "propose an explainable deep neural networks(DNN)-based method for automatic\n",
              "detection of COVID-19 symptoms from CXR images, which we call\n",
              "'DeepCOVIDExplainer'. We used 16,995 CXR images across 13,808 patients,\n",
              "covering normal, pneumonia, and COVID-19 cases. CXR images are first\n",
              "comprehensively preprocessed, before being augmented and classified with a\n",
              "neural ensemble method, followed by highlighting class-discriminating regions\n",
              "using gradient-guided class activation maps(Grad-CAM++) and layer-wise\n",
              "relevance propagation(LRP). Further, we provide human-interpretable\n",
              "explanations of the predictions. Evaluation results based on hold-out data show\n",
              "that our approach can identify COVID-19 confidently with a positive predictive\n",
              "value(PPV) of 89.61% and recall of 83%, improving over recent comparable\n",
              "approaches. We hope that our findings will be a useful contribution to the\n",
              "fight against COVID-19 and, in more general, towards an increasing acceptance\n",
              "and adoption of AI-assisted applications in the clinical practice.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row74_col2\" class=\"data row74 col2\" ><a href=\"https://arxiv.org/abs/2004.04582\">https://arxiv.org/abs/2004.04582</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row75\" class=\"row_heading level0 row75\" >75</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row75_col0\" class=\"data row75 col0\" >Challenges in Forecasting Malicious Events from Incomplete Data</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row75_col1\" class=\"data row75 col1\" >The ability to accurately predict cyber-attacks would enable organizations to\n",
              "mitigate their growing threat and avert the financial losses and disruptions\n",
              "they cause. But how predictable are cyber-attacks? Researchers have attempted\n",
              "to combine external data -- ranging from vulnerability disclosures to\n",
              "discussions on Twitter and the darkweb -- with machine learning algorithms to\n",
              "learn indicators of impending cyber-attacks. However, successful cyber-attacks\n",
              "represent a tiny fraction of all attempted attacks: the vast majority are\n",
              "stopped, or filtered by the security appliances deployed at the target. As we\n",
              "show in this paper, the process of filtering reduces the predictability of\n",
              "cyber-attacks. The small number of attacks that do penetrate the target's\n",
              "defenses follow a different generative process compared to the whole data which\n",
              "is much harder to learn for predictive models. This could be caused by the fact\n",
              "that the resulting time series also depends on the filtering process in\n",
              "addition to all the different factors that the original time series depended\n",
              "on. We empirically quantify the loss of predictability due to filtering using\n",
              "real-world data from two organizations. Our work identifies the limits to\n",
              "forecasting cyber-attacks from highly filtered data.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row75_col2\" class=\"data row75 col2\" ><a href=\"https://arxiv.org/abs/2004.04597\">https://arxiv.org/abs/2004.04597</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row76\" class=\"row_heading level0 row76\" >76</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row76_col0\" class=\"data row76 col0\" >Adaptive optics with reflected light and deep neural networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row76_col1\" class=\"data row76 col1\" >Light scattering and aberrations limit optical microscopy in biological\n",
              "tissue, which motivates the development of adaptive optics techniques. Here, we\n",
              "develop a method for adaptive optics with reflected light and deep neural\n",
              "networks compatible with an epi-detection configuration. Large datasets of\n",
              "sample aberrations which consist of excitation and detection path aberrations\n",
              "as well as the corresponding reflected focus images are generated. These\n",
              "datasets are used for training deep neural networks. After training, these\n",
              "networks can disentangle and independently correct excitation and detection\n",
              "aberrations based on reflected light images recorded from scattering samples. A\n",
              "similar deep learning approach is also demonstrated with scattering guide\n",
              "stars. The predicted aberration corrections are validated using two photon\n",
              "imaging.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row76_col2\" class=\"data row76 col2\" ><a href=\"https://arxiv.org/abs/2004.04603\">https://arxiv.org/abs/2004.04603</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row77\" class=\"row_heading level0 row77\" >77</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row77_col0\" class=\"data row77 col0\" >Private Knowledge Transfer via Model Distillation with Generative  Adversarial Networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row77_col1\" class=\"data row77 col1\" >The deployment of deep learning applications has to address the growing\n",
              "privacy concerns when using private and sensitive data for training. A\n",
              "conventional deep learning model is prone to privacy attacks that can recover\n",
              "the sensitive information of individuals from either model parameters or\n",
              "accesses to the target model. Recently, differential privacy that offers\n",
              "provable privacy guarantees has been proposed to train neural networks in a\n",
              "privacy-preserving manner to protect training data. However, many approaches\n",
              "tend to provide the worst case privacy guarantees for model publishing,\n",
              "inevitably impairing the accuracy of the trained models. In this paper, we\n",
              "present a novel private knowledge transfer strategy, where the private teacher\n",
              "trained on sensitive data is not publicly accessible but teaches a student to\n",
              "be publicly released. In particular, a three-player\n",
              "(teacher-student-discriminator) learning framework is proposed to achieve\n",
              "trade-off between utility and privacy, where the student acquires the distilled\n",
              "knowledge from the teacher and is trained with the discriminator to generate\n",
              "similar outputs as the teacher. We then integrate a differential privacy\n",
              "protection mechanism into the learning procedure, which enables a rigorous\n",
              "privacy budget for the training. The framework eventually allows student to be\n",
              "trained with only unlabelled public data and very few epochs, and hence\n",
              "prevents the exposure of sensitive training data, while ensuring model utility\n",
              "with a modest privacy budget. The experiments on MNIST, SVHN and CIFAR-10\n",
              "datasets show that our students obtain the accuracy losses w.r.t teachers of\n",
              "0.89%, 2.29%, 5.16%, respectively with the privacy bounds of (1.93, 10^-5),\n",
              "(5.02, 10^-6), (8.81, 10^-6). When compared with the existing works\n",
              "\\cite{papernot2016semi,wang2019private}, the proposed work can achieve 5-82%\n",
              "accuracy loss improvement.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row77_col2\" class=\"data row77 col2\" ><a href=\"https://arxiv.org/abs/2004.04631\">https://arxiv.org/abs/2004.04631</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row78\" class=\"row_heading level0 row78\" >78</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row78_col0\" class=\"data row78 col0\" >TuiGAN: Learning Versatile Image-to-Image Translation with Two Unpaired  Images</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row78_col1\" class=\"data row78 col1\" >An unsupervised image-to-image translation (UI2I) task deals with learning a\n",
              "mapping between two domains without paired images. While existing UI2I methods\n",
              "usually require numerous unpaired images from different domains for training,\n",
              "there are many scenarios where training data is quite limited. In this paper,\n",
              "we argue that even if each domain contains a single image, UI2I can still be\n",
              "achieved. To this end, we propose TuiGAN, a generative model that is trained on\n",
              "only two unpaired images and amounts to one-shot unsupervised learning. With\n",
              "TuiGAN, an image is translated in a coarse-to-fine manner where the generated\n",
              "image is gradually refined from global structures to local details. We conduct\n",
              "extensive experiments to verify that our versatile method can outperform strong\n",
              "baselines on a wide variety of UI2I tasks. Moreover, TuiGAN is capable of\n",
              "achieving comparable performance with the state-of-the-art UI2I models trained\n",
              "with sufficient data.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row78_col2\" class=\"data row78 col2\" ><a href=\"https://arxiv.org/abs/2004.04634\">https://arxiv.org/abs/2004.04634</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row79\" class=\"row_heading level0 row79\" >79</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row79_col0\" class=\"data row79 col0\" >Adversarial Genetic Programming for Cyber Security: A Rising Application  Domain Where GP Matters</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row79_col1\" class=\"data row79 col1\" >Cyber security adversaries and engagements are ubiquitous and ceaseless. We\n",
              "delineate Adversarial Genetic Programming for Cyber Security, a research topic\n",
              "that, by means of genetic programming (GP), replicates and studies the behavior\n",
              "of cyber adversaries and the dynamics of their engagements. Adversarial Genetic\n",
              "Programming for Cyber Security encompasses extant and immediate research\n",
              "efforts in a vital problem domain, arguably occupying a position at the\n",
              "frontier where GP matters. Additionally, it prompts research questions around\n",
              "evolving complex behavior by expressing different abstractions with GP and\n",
              "opportunities to reconnect to the Machine Learning, Artificial Life,\n",
              "Agent-Based Modeling and Cyber Security communities. We present a framework\n",
              "called RIVALS which supports the study of network security arms races. Its goal\n",
              "is to elucidate the dynamics of cyber networks under attack by computationally\n",
              "modeling and simulating them.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row79_col2\" class=\"data row79 col2\" ><a href=\"https://arxiv.org/abs/2004.04647\">https://arxiv.org/abs/2004.04647</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row80\" class=\"row_heading level0 row80\" >80</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row80_col0\" class=\"data row80 col0\" >State-Only Imitation Learning for Dexterous Manipulation</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row80_col1\" class=\"data row80 col1\" >Dexterous manipulation has been a long-standing challenge in robotics.\n",
              "Recently, modern model-free RL has demonstrated impressive results on a number\n",
              "of problems. However, complex domains like dexterous manipulation remain a\n",
              "challenge for RL due to the poor sample complexity. To address this, current\n",
              "approaches employ expert demonstrations in the form of state-action pairs,\n",
              "which are difficult to obtain for real-world settings such as learning from\n",
              "videos. In this work, we move toward a more realistic setting and explore\n",
              "state-only imitation learning. To tackle this setting, we train an inverse\n",
              "dynamics model and use it to predict actions for state-only demonstrations. The\n",
              "inverse dynamics model and the policy are trained jointly. Our method performs\n",
              "on par with state-action approaches and considerably outperforms RL alone. By\n",
              "not relying on expert actions, we are able to learn from demonstrations with\n",
              "different dynamics, morphologies, and objects.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row80_col2\" class=\"data row80 col2\" ><a href=\"https://arxiv.org/abs/2004.04650\">https://arxiv.org/abs/2004.04650</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row81\" class=\"row_heading level0 row81\" >81</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row81_col0\" class=\"data row81 col0\" >Exploration with Limited Memory: Streaming Algorithms for Coin Tossing,  Noisy Comparisons, and Multi-Armed Bandits</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row81_col1\" class=\"data row81 col1\" >Consider the following abstract coin tossing problem: Given a set of $n$\n",
              "coins with unknown biases, find the most biased coin using a minimal number of\n",
              "coin tosses. This is a common abstraction of various exploration problems in\n",
              "theoretical computer science and machine learning and has been studied\n",
              "extensively over the years. In particular, algorithms with optimal sample\n",
              "complexity (number of coin tosses) have been known for this problem for quite\n",
              "some time.\n",
              "Motivated by applications to processing massive datasets, we study the space\n",
              "complexity of solving this problem with optimal number of coin tosses in the\n",
              "streaming model. In this model, the coins are arriving one by one and the\n",
              "algorithm is only allowed to store a limited number of coins at any point --\n",
              "any coin not present in the memory is lost and can no longer be tossed or\n",
              "compared to arriving coins. Prior algorithms for the coin tossing problem with\n",
              "optimal sample complexity are based on iterative elimination of coins which\n",
              "inherently require storing all the coins, leading to memory-inefficient\n",
              "streaming algorithms.\n",
              "We remedy this state-of-affairs by presenting a series of improved streaming\n",
              "algorithms for this problem: we start with a simple algorithm which require\n",
              "storing only $O(\\log{n})$ coins and then iteratively refine it further and\n",
              "further, leading to algorithms with $O(\\log\\log{(n)})$ memory, $O(\\log^*{(n)})$\n",
              "memory, and finally a one that only stores a single extra coin in memory -- the\n",
              "same exact space needed to just store the best coin throughout the stream.\n",
              "Furthermore, we extend our algorithms to the problem of finding the $k$ most\n",
              "biased coins as well as other exploration problems such as finding top-$k$\n",
              "elements using noisy comparisons or finding an $\\epsilon$-best arm in\n",
              "stochastic multi-armed bandits, and obtain efficient streaming algorithms for\n",
              "these problems.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row81_col2\" class=\"data row81 col2\" ><a href=\"https://arxiv.org/abs/2004.04666\">https://arxiv.org/abs/2004.04666</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row82\" class=\"row_heading level0 row82\" >82</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row82_col0\" class=\"data row82 col0\" >Test-Time Adaptable Neural Networks for Robust Medical Image  Segmentation</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row82_col1\" class=\"data row82 col1\" >Convolutional Neural Networks (CNNs) work very well for supervised learning\n",
              "problems when the training dataset is representative of the variations expected\n",
              "to be encountered at test time. In medical image segmentation, this premise is\n",
              "violated when there is a mismatch between training and test images in terms of\n",
              "their acquisition details, such as the scanner model or the protocol.\n",
              "Remarkable performance degradation of CNNs in this scenario is well documented\n",
              "in the literature. To address this problem, we design the segmentation CNN as a\n",
              "concatenation of two sub-networks: a relatively shallow image normalization\n",
              "CNN, followed by a deep CNN that segments the normalized image. We train both\n",
              "these sub-networks using a training dataset, consisting of annotated images\n",
              "from a particular scanner and protocol setting. Now, at test time, we adapt the\n",
              "image normalization sub-network for each test image, guided by an implicit\n",
              "prior on the predicted segmentation labels. We employ an independently trained\n",
              "denoising autoencoder (DAE) in order to model such an implicit prior on\n",
              "plausible anatomical segmentation labels. We validate the proposed idea on\n",
              "multi-center Magnetic Resonance imaging datasets of three anatomies: brain,\n",
              "heart and prostate. The proposed test-time adaptation consistently provides\n",
              "performance improvement, demonstrating the promise and generality of the\n",
              "approach. Being agnostic to the architecture of the deep CNN, the second\n",
              "sub-network, the proposed design can be utilized with any segmentation network\n",
              "to increase robustness to variations in imaging scanners and protocols.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row82_col2\" class=\"data row82 col2\" ><a href=\"https://arxiv.org/abs/2004.04668\">https://arxiv.org/abs/2004.04668</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row83\" class=\"row_heading level0 row83\" >83</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row83_col0\" class=\"data row83 col0\" >Predicting human-generated bitstreams using classical and quantum models</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row83_col1\" class=\"data row83 col1\" >A school of thought contends that human decision making exhibits quantum-like\n",
              "logic. While it is not known whether the brain may indeed be driven by actual\n",
              "quantum mechanisms, some researchers suggest that the decision logic is\n",
              "phenomenologically non-classical. This paper develops and implements an\n",
              "empirical framework to explore this view. We emulate binary decision-making\n",
              "using low width, low depth, parameterized quantum circuits. Here, entanglement\n",
              "serves as a resource for pattern analysis in the context of a simple\n",
              "bit-prediction game. We evaluate a hybrid quantum-assisted machine learning\n",
              "strategy where quantum processing is used to detect correlations in the\n",
              "bitstreams while parameter updates and class inference are performed by\n",
              "classical post-processing of measurement results. Simulation results indicate\n",
              "that a family of two-qubit variational circuits is sufficient to achieve the\n",
              "same bit-prediction accuracy as the best traditional classical solution such as\n",
              "neural nets or logistic autoregression. Thus, short of establishing a provable\n",
              "\"quantum advantage\" in this simple scenario, we give evidence that the\n",
              "classical predictability analysis of a human-generated bitstream can be\n",
              "achieved by small quantum models.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row83_col2\" class=\"data row83 col2\" ><a href=\"https://arxiv.org/abs/2004.04671\">https://arxiv.org/abs/2004.04671</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row84\" class=\"row_heading level0 row84\" >84</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row84_col0\" class=\"data row84 col0\" >An Overview of Federated Deep Learning Privacy Attacks and Defensive  Strategies</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row84_col1\" class=\"data row84 col1\" >With the increased attention and legislation for data-privacy, collaborative\n",
              "machine learning (ML) algorithms are being developed to ensure the protection\n",
              "of private data used for processing. Federated learning (FL) is the most\n",
              "popular of these methods, which provides privacy preservation by facilitating\n",
              "collaborative training of a shared model without the need to exchange any\n",
              "private data with a centralized server. Rather, an abstraction of the data in\n",
              "the form of a machine learning model update is sent. Recent studies showed that\n",
              "such model updates may still very well leak private information and thus more\n",
              "structured risk assessment is needed. In this paper, we analyze existing\n",
              "vulnerabilities of FL and subsequently perform a literature review of the\n",
              "possible attack methods targetingFL privacy protection capabilities. These\n",
              "attack methods are then categorized by a basic taxonomy. Additionally, we\n",
              "provide a literature study of the most recent defensive strategies and\n",
              "algorithms for FL aimed to overcome these attacks. These defensive strategies\n",
              "are categorized by their respective underlying defence principle. The paper\n",
              "concludes that the application of a single defensive strategy is not enough to\n",
              "provide adequate protection to all available attack methods.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row84_col2\" class=\"data row84 col2\" ><a href=\"https://arxiv.org/abs/2004.04676\">https://arxiv.org/abs/2004.04676</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row85\" class=\"row_heading level0 row85\" >85</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row85_col0\" class=\"data row85 col0\" >Rethinking the Trigger of Backdoor Attack</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row85_col1\" class=\"data row85 col1\" >In this work, we study the problem of backdoor attacks, which add a specific\n",
              "trigger ($i.e.$, a local patch) onto some training images to enforce that the\n",
              "testing images with the same trigger are incorrectly predicted while the\n",
              "natural testing examples are correctly predicted by the trained model. Many\n",
              "existing works adopted the setting that the triggers across the training and\n",
              "testing images follow the same appearance and are located at the same area.\n",
              "However, we observe that if the appearance or location of the trigger is\n",
              "slightly changed, then the attack performance may degrade sharply. According to\n",
              "this observation, we propose to spatially transform ($e.g.$, flipping and\n",
              "scaling) the testing image, such that the appearance and location of the\n",
              "trigger (if exists) will be changed. This simple strategy is experimentally\n",
              "verified to be effective to defend many state-of-the-art backdoor attack\n",
              "methods. Furthermore, to enhance the robustness of the backdoor attacks, we\n",
              "propose to conduct the random spatial transformation on the training images\n",
              "with the trigger before feeding into the training process. Extensive\n",
              "experiments verify that the proposed backdoor attack is robust to spatial\n",
              "transformations.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row85_col2\" class=\"data row85 col2\" ><a href=\"https://arxiv.org/abs/2004.04692\">https://arxiv.org/abs/2004.04692</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row86\" class=\"row_heading level0 row86\" >86</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row86_col0\" class=\"data row86 col0\" >Learning to Drive Off Road on Smooth Terrain in Unstructured  Environments Using an On-Board Camera and Sparse Aerial Images</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row86_col1\" class=\"data row86 col1\" >We present a method for learning to drive on smooth terrain while\n",
              "simultaneously avoiding collisions in challenging off-road and unstructured\n",
              "outdoor environments using only visual inputs. Our approach applies a hybrid\n",
              "model-based and model-free reinforcement learning method that is entirely\n",
              "self-supervised in labeling terrain roughness and collisions using on-board\n",
              "sensors. Notably, we provide both first-person and overhead aerial image inputs\n",
              "to our model. We find that the fusion of these complementary inputs improves\n",
              "planning foresight and makes the model robust to visual obstructions. Our\n",
              "results show the ability to generalize to environments with plentiful\n",
              "vegetation, various types of rock, and sandy trails. During evaluation, our\n",
              "policy attained 90% smooth terrain traversal and reduced the proportion of\n",
              "rough terrain driven over by 6.1 times compared to a model using only\n",
              "first-person imagery.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row86_col2\" class=\"data row86 col2\" ><a href=\"https://arxiv.org/abs/2004.04697\">https://arxiv.org/abs/2004.04697</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row87\" class=\"row_heading level0 row87\" >87</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row87_col0\" class=\"data row87 col0\" >Multiclass Classification via Class-Weighted Nearest Neighbors</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row87_col1\" class=\"data row87 col1\" >We study statistical properties of the k-nearest neighbors algorithm for\n",
              "multiclass classification, with a focus on settings where the number of classes\n",
              "may be large and/or classes may be highly imbalanced. In particular, we\n",
              "consider a variant of the k-nearest neighbor classifier with non-uniform\n",
              "class-weightings, for which we derive upper and minimax lower bounds on\n",
              "accuracy, class-weighted risk, and uniform error. Additionally, we show that\n",
              "uniform error bounds lead to bounds on the difference between empirical\n",
              "confusion matrix quantities and their population counterparts across a set of\n",
              "weights. As a result, we may adjust the class weights to optimize\n",
              "classification metrics such as F1 score or Matthew's Correlation Coefficient\n",
              "that are commonly used in practice, particularly in settings with imbalanced\n",
              "classes. We additionally provide a simple example to instantiate our bounds and\n",
              "numerical experiments.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row87_col2\" class=\"data row87 col2\" ><a href=\"https://arxiv.org/abs/2004.04715\">https://arxiv.org/abs/2004.04715</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row88\" class=\"row_heading level0 row88\" >88</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row88_col0\" class=\"data row88 col0\" >Industrial Forecasting with Exponentially Smoothed Recurrent Neural  Networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row88_col1\" class=\"data row88 col1\" >Industrial forecasting has entered an era of unprecedented growth in the size\n",
              "and complexity of data which require new modeling methodologies. While many new\n",
              "general purpose machine learning approaches have emerged, they remain poorly\n",
              "understand and irreconcilable with more traditional statistical modeling\n",
              "approaches. We present a general class of exponential smoothed recurrent neural\n",
              "networks (RNNs) which are well suited to modeling non-stationary dynamical\n",
              "systems arising in industrial applications such as electricity load management\n",
              "and financial risk and trading. In particular, we analyze their capacity to\n",
              "characterize the non-linear partial autocorrelation structure of time series\n",
              "and directly capture dynamic effects such as seasonality and regime changes.\n",
              "Application of exponentially smoothed RNNs to electricity load forecasting,\n",
              "weather data and financial time series, such as minute level Bitcoin prices and\n",
              "CME futures tick data, highlight the efficacy of exponential smoothing for\n",
              "multi-step time series forecasting. The results also suggest that popular, but\n",
              "more complicated neural network architectures originally designed for speech\n",
              "processing, such as LSTMs and GRUs, are likely over-engineered for industrial\n",
              "forecasting and light-weight exponentially smoothed architectures capture the\n",
              "salient features while being superior and more robust than simple RNNs.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row88_col2\" class=\"data row88 col2\" ><a href=\"https://arxiv.org/abs/2004.04717\">https://arxiv.org/abs/2004.04717</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row89\" class=\"row_heading level0 row89\" >89</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row89_col0\" class=\"data row89 col0\" >On Linear Stochastic Approximation: Fine-grained Polyak-Ruppert and  Non-Asymptotic Concentration</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row89_col1\" class=\"data row89 col1\" >We undertake a precise study of the asymptotic and non-asymptotic properties\n",
              "of stochastic approximation procedures with Polyak-Ruppert averaging for\n",
              "solving a linear system $\\bar{A} \\theta = \\bar{b}$. When the matrix $\\bar{A}$\n",
              "is Hurwitz, we prove a central limit theorem (CLT) for the averaged iterates\n",
              "with fixed step size and number of iterations going to infinity. The CLT\n",
              "characterizes the exact asymptotic covariance matrix, which is the sum of the\n",
              "classical Polyak-Ruppert covariance and a correction term that scales with the\n",
              "step size. Under assumptions on the tail of the noise distribution, we prove a\n",
              "non-asymptotic concentration inequality whose main term matches the covariance\n",
              "in CLT in any direction, up to universal constants. When the matrix $\\bar{A}$\n",
              "is not Hurwitz but only has non-negative real parts in its eigenvalues, we\n",
              "prove that the averaged LSA procedure actually achieves an $O(1/T)$ rate in\n",
              "mean-squared error. Our results provide a more refined understanding of linear\n",
              "stochastic approximation in both the asymptotic and non-asymptotic settings. We\n",
              "also show various applications of the main results, including the study of\n",
              "momentum-based stochastic gradient methods as well as temporal difference\n",
              "algorithms in reinforcement learning.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row89_col2\" class=\"data row89 col2\" ><a href=\"https://arxiv.org/abs/2004.04719\">https://arxiv.org/abs/2004.04719</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row90\" class=\"row_heading level0 row90\" >90</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row90_col0\" class=\"data row90 col0\" >Translation Artifacts in Cross-lingual Transfer Learning</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row90_col1\" class=\"data row90 col1\" >Both human and machine translation play a central role in cross-lingual\n",
              "transfer learning: many multilingual datasets have been created through\n",
              "professional translation services, and using machine translation to translate\n",
              "either the test set or the training set is a widely used transfer technique. In\n",
              "this paper, we show that such translation process can introduce subtle\n",
              "artifacts that have a notable impact in existing cross-lingual models. For\n",
              "instance, in natural language inference, translating the premise and the\n",
              "hypothesis independently can reduce the lexical overlap between them, which\n",
              "current models are highly sensitive to. We show that some previous findings in\n",
              "cross-lingual transfer learning need to be reconsidered in the light of this\n",
              "phenomenon. Based on the gained insights, we also improve the state-of-the-art\n",
              "in XNLI for the translate-test and zero-shot approaches by 4.3 and 2.8 points,\n",
              "respectively.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row90_col2\" class=\"data row90 col2\" ><a href=\"https://arxiv.org/abs/2004.04721\">https://arxiv.org/abs/2004.04721</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row91\" class=\"row_heading level0 row91\" >91</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row91_col0\" class=\"data row91 col0\" >Re-conceptualising the Language Game Paradigm in the Framework of  Multi-Agent Reinforcement Learning</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row91_col1\" class=\"data row91 col1\" >In this paper, we formulate the challenge of re-conceptualising the language\n",
              "game experimental paradigm in the framework of multi-agent reinforcement\n",
              "learning (MARL). If successful, future language game experiments will benefit\n",
              "from the rapid and promising methodological advances in the MARL community,\n",
              "while future MARL experiments on learning emergent communication will benefit\n",
              "from the insights and results gained from language game experiments. We\n",
              "strongly believe that this cross-pollination has the potential to lead to major\n",
              "breakthroughs in the modelling of how human-like languages can emerge and\n",
              "evolve in multi-agent systems.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row91_col2\" class=\"data row91 col2\" ><a href=\"https://arxiv.org/abs/2004.04722\">https://arxiv.org/abs/2004.04722</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row92\" class=\"row_heading level0 row92\" >92</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row92_col0\" class=\"data row92 col0\" >Instance-aware, Context-focused, and Memory-efficient Weakly Supervised  Object Detection</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row92_col1\" class=\"data row92 col1\" >Weakly supervised learning has emerged as a compelling tool for object\n",
              "detection by reducing the need for strong supervision during training. However,\n",
              "major challenges remain: (1) differentiation of object instances can be\n",
              "ambiguous; (2) detectors tend to focus on discriminative parts rather than\n",
              "entire objects; (3) without ground truth, object proposals have to be redundant\n",
              "for high recalls, causing significant memory consumption. Addressing these\n",
              "challenges is difficult, as it often requires to eliminate uncertainties and\n",
              "trivial solutions. To target these issues we develop an instance-aware and\n",
              "context-focused unified framework. It employs an instance-aware self-training\n",
              "algorithm and a learnable Concrete DropBlock while devising a memory-efficient\n",
              "sequential batch back-propagation. Our proposed method achieves\n",
              "state-of-the-art results on COCO ($12.1\\% ~AP$, $24.8\\% ~AP_{50}$), VOC 2007\n",
              "($54.9\\% ~AP$), and VOC 2012 ($52.1\\% ~AP$), improving baselines by great\n",
              "margins. In addition, the proposed method is the first to benchmark ResNet\n",
              "based models and weakly supervised video object detection. Refer to our project\n",
              "page for code, models, and more details: https://github.com/NVlabs/wetectron.\n",
              "</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row92_col2\" class=\"data row92 col2\" ><a href=\"https://arxiv.org/abs/2004.04725\">https://arxiv.org/abs/2004.04725</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row93\" class=\"row_heading level0 row93\" >93</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row93_col0\" class=\"data row93 col0\" >DPVis: Visual Analytics with Hidden Markov Models for Disease  Progression Pathways</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row93_col1\" class=\"data row93 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row93_col2\" class=\"data row93 col2\" ><a href=\"https://arxiv.org/abs/1904.11652\">https://arxiv.org/abs/1904.11652</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row94\" class=\"row_heading level0 row94\" >94</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row94_col0\" class=\"data row94 col0\" >A Fine-Grained Spectral Perspective on Neural Networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row94_col1\" class=\"data row94 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row94_col2\" class=\"data row94 col2\" ><a href=\"https://arxiv.org/abs/1907.10599\">https://arxiv.org/abs/1907.10599</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row95\" class=\"row_heading level0 row95\" >95</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row95_col0\" class=\"data row95 col0\" >Resonant Machine Learning Based on Complex Growth Transform Dynamical  Systems</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row95_col1\" class=\"data row95 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row95_col2\" class=\"data row95 col2\" ><a href=\"https://arxiv.org/abs/1908.05377\">https://arxiv.org/abs/1908.05377</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row96\" class=\"row_heading level0 row96\" >96</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row96_col0\" class=\"data row96 col0\" >Teaching Vehicles to Anticipate: A Systematic Study on Probabilistic  Behavior Prediction Using Large Data Sets</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row96_col1\" class=\"data row96 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row96_col2\" class=\"data row96 col2\" ><a href=\"https://arxiv.org/abs/1910.07772\">https://arxiv.org/abs/1910.07772</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row97\" class=\"row_heading level0 row97\" >97</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row97_col0\" class=\"data row97 col0\" >A Prototypical Triplet Loss for Cover Detection</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row97_col1\" class=\"data row97 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row97_col2\" class=\"data row97 col2\" ><a href=\"https://arxiv.org/abs/1910.09862\">https://arxiv.org/abs/1910.09862</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row98\" class=\"row_heading level0 row98\" >98</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row98_col0\" class=\"data row98 col0\" >Adversarial target-invariant representation learning for domain  generalization</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row98_col1\" class=\"data row98 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row98_col2\" class=\"data row98 col2\" ><a href=\"https://arxiv.org/abs/1911.00804\">https://arxiv.org/abs/1911.00804</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row99\" class=\"row_heading level0 row99\" >99</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row99_col0\" class=\"data row99 col0\" >Optimal No-regret Learning in Repeated First-price Auctions</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row99_col1\" class=\"data row99 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row99_col2\" class=\"data row99 col2\" ><a href=\"https://arxiv.org/abs/2003.09795\">https://arxiv.org/abs/2003.09795</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row100\" class=\"row_heading level0 row100\" >100</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row100_col0\" class=\"data row100 col0\" >Robust and On-the-fly Dataset Denoising for Image Classification</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row100_col1\" class=\"data row100 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row100_col2\" class=\"data row100 col2\" ><a href=\"https://arxiv.org/abs/2003.10647\">https://arxiv.org/abs/2003.10647</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row101\" class=\"row_heading level0 row101\" >101</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row101_col0\" class=\"data row101 col0\" >Unpacking Information Bottlenecks: Unifying Information-Theoretic  Objectives in Deep Learning</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row101_col1\" class=\"data row101 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row101_col2\" class=\"data row101 col2\" ><a href=\"https://arxiv.org/abs/2003.12537\">https://arxiv.org/abs/2003.12537</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row102\" class=\"row_heading level0 row102\" >102</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row102_col0\" class=\"data row102 col0\" >How Not to Give a FLOP: Combining Regularization and Pruning for  Efficient Inference</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row102_col1\" class=\"data row102 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row102_col2\" class=\"data row102 col2\" ><a href=\"https://arxiv.org/abs/2003.13593\">https://arxiv.org/abs/2003.13593</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row103\" class=\"row_heading level0 row103\" >103</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row103_col0\" class=\"data row103 col0\" >Leverage the Average: an Analysis of Regularization in RL</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row103_col1\" class=\"data row103 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row103_col2\" class=\"data row103 col2\" ><a href=\"https://arxiv.org/abs/2003.14089\">https://arxiv.org/abs/2003.14089</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row104\" class=\"row_heading level0 row104\" >104</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row104_col0\" class=\"data row104 col0\" >XtracTree for Regulator Validation of Bagging Methods Used in Retail  Banking</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row104_col1\" class=\"data row104 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row104_col2\" class=\"data row104 col2\" ><a href=\"https://arxiv.org/abs/2004.02326\">https://arxiv.org/abs/2004.02326</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row105\" class=\"row_heading level0 row105\" >105</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row105_col0\" class=\"data row105 col0\" >Evolving Normalization-Activation Layers</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row105_col1\" class=\"data row105 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row105_col2\" class=\"data row105 col2\" ><a href=\"https://arxiv.org/abs/2004.02967\">https://arxiv.org/abs/2004.02967</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row106\" class=\"row_heading level0 row106\" >106</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row106_col0\" class=\"data row106 col0\" >A Polynomial Neural Network with Controllable Precision and  Human-Readable Topology for Prediction and System Identification</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row106_col1\" class=\"data row106 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row106_col2\" class=\"data row106 col2\" ><a href=\"https://arxiv.org/abs/2004.03955\">https://arxiv.org/abs/2004.03955</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row107\" class=\"row_heading level0 row107\" >107</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row107_col0\" class=\"data row107 col0\" >A Centralized Multi-stage Non-parametric Learning Algorithm for  Opportunistic Spectrum Access</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row107_col1\" class=\"data row107 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row107_col2\" class=\"data row107 col2\" ><a href=\"https://arxiv.org/abs/1804.11135\">https://arxiv.org/abs/1804.11135</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row108\" class=\"row_heading level0 row108\" >108</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row108_col0\" class=\"data row108 col0\" >Performance of Johnson-Lindenstrauss Transform for k-Means and k-Medians  Clustering</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row108_col1\" class=\"data row108 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row108_col2\" class=\"data row108 col2\" ><a href=\"https://arxiv.org/abs/1811.03195\">https://arxiv.org/abs/1811.03195</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row109\" class=\"row_heading level0 row109\" >109</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row109_col0\" class=\"data row109 col0\" >Optimizing Quantum Error Correction Codes with Reinforcement Learning</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row109_col1\" class=\"data row109 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row109_col2\" class=\"data row109 col2\" ><a href=\"https://arxiv.org/abs/1812.08451\">https://arxiv.org/abs/1812.08451</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row110\" class=\"row_heading level0 row110\" >110</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row110_col0\" class=\"data row110 col0\" >High-dimensional Bayesian optimization using low-dimensional feature  spaces</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row110_col1\" class=\"data row110 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row110_col2\" class=\"data row110 col2\" ><a href=\"https://arxiv.org/abs/1902.10675\">https://arxiv.org/abs/1902.10675</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row111\" class=\"row_heading level0 row111\" >111</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row111_col0\" class=\"data row111 col0\" >Guiding Inferences in Connection Tableau by Recurrent Neural Networks</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row111_col1\" class=\"data row111 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row111_col2\" class=\"data row111 col2\" ><a href=\"https://arxiv.org/abs/1905.07961\">https://arxiv.org/abs/1905.07961</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row112\" class=\"row_heading level0 row112\" >112</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row112_col0\" class=\"data row112 col0\" >Regularizing Neural Networks via Minimizing Hyperspherical Energy</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row112_col1\" class=\"data row112 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row112_col2\" class=\"data row112 col2\" ><a href=\"https://arxiv.org/abs/1906.04892\">https://arxiv.org/abs/1906.04892</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row113\" class=\"row_heading level0 row113\" >113</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row113_col0\" class=\"data row113 col0\" >Generator evaluator-selector net for panoptic image segmentation and  splitting unfamiliar objects into parts</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row113_col1\" class=\"data row113 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row113_col2\" class=\"data row113 col2\" ><a href=\"https://arxiv.org/abs/1908.09108\">https://arxiv.org/abs/1908.09108</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row114\" class=\"row_heading level0 row114\" >114</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row114_col0\" class=\"data row114 col0\" >Multilingual Graphemic Hybrid ASR with Massive Data Augmentation</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row114_col1\" class=\"data row114 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row114_col2\" class=\"data row114 col2\" ><a href=\"https://arxiv.org/abs/1909.06522\">https://arxiv.org/abs/1909.06522</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row115\" class=\"row_heading level0 row115\" >115</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row115_col0\" class=\"data row115 col0\" >Conservative set valued fields, automatic differentiation, stochastic  gradient method and deep learning</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row115_col1\" class=\"data row115 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row115_col2\" class=\"data row115 col2\" ><a href=\"https://arxiv.org/abs/1909.10300\">https://arxiv.org/abs/1909.10300</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row116\" class=\"row_heading level0 row116\" >116</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row116_col0\" class=\"data row116 col0\" >Structured Pruning of a BERT-based Question Answering Model</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row116_col1\" class=\"data row116 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row116_col2\" class=\"data row116 col2\" ><a href=\"https://arxiv.org/abs/1910.06360\">https://arxiv.org/abs/1910.06360</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row117\" class=\"row_heading level0 row117\" >117</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row117_col0\" class=\"data row117 col0\" >Compact Network Training for Person ReID</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row117_col1\" class=\"data row117 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row117_col2\" class=\"data row117 col2\" ><a href=\"https://arxiv.org/abs/1910.07038\">https://arxiv.org/abs/1910.07038</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row118\" class=\"row_heading level0 row118\" >118</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row118_col0\" class=\"data row118 col0\" >Data Diversification: An Elegant Strategy For Neural Machine Translation</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row118_col1\" class=\"data row118 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row118_col2\" class=\"data row118 col2\" ><a href=\"https://arxiv.org/abs/1911.01986\">https://arxiv.org/abs/1911.01986</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row119\" class=\"row_heading level0 row119\" >119</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row119_col0\" class=\"data row119 col0\" >Deep Contextualized Acoustic Representations For Semi-Supervised Speech  Recognition</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row119_col1\" class=\"data row119 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row119_col2\" class=\"data row119 col2\" ><a href=\"https://arxiv.org/abs/1912.01679\">https://arxiv.org/abs/1912.01679</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row120\" class=\"row_heading level0 row120\" >120</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row120_col0\" class=\"data row120 col0\" >GhostImage: Perception Domain Attacks against Vision-based Object  Classification Systems</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row120_col1\" class=\"data row120 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row120_col2\" class=\"data row120 col2\" ><a href=\"https://arxiv.org/abs/2001.07792\">https://arxiv.org/abs/2001.07792</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row121\" class=\"row_heading level0 row121\" >121</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row121_col0\" class=\"data row121 col0\" >Superpixel Segmentation via Convolutional Neural Networks with  Regularized Information Maximization</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row121_col1\" class=\"data row121 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row121_col2\" class=\"data row121 col2\" ><a href=\"https://arxiv.org/abs/2002.06765\">https://arxiv.org/abs/2002.06765</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row122\" class=\"row_heading level0 row122\" >122</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row122_col0\" class=\"data row122 col0\" >A Time-dependent SIR model for COVID-19 with Undetectable Infected  Persons</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row122_col1\" class=\"data row122 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row122_col2\" class=\"data row122 col2\" ><a href=\"https://arxiv.org/abs/2003.00122\">https://arxiv.org/abs/2003.00122</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row123\" class=\"row_heading level0 row123\" >123</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row123_col0\" class=\"data row123 col0\" >An Empirical Accuracy Law for Sequential Machine Translation: the Case  of Google Translate</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row123_col1\" class=\"data row123 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row123_col2\" class=\"data row123 col2\" ><a href=\"https://arxiv.org/abs/2003.02817\">https://arxiv.org/abs/2003.02817</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row124\" class=\"row_heading level0 row124\" >124</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row124_col0\" class=\"data row124 col0\" >Deep Deterministic Portfolio Optimization</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row124_col1\" class=\"data row124 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row124_col2\" class=\"data row124 col2\" ><a href=\"https://arxiv.org/abs/2003.06497\">https://arxiv.org/abs/2003.06497</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row125\" class=\"row_heading level0 row125\" >125</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row125_col0\" class=\"data row125 col0\" >RNE: A Scalable Network Embedding for Billion-scale Recommendation</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row125_col1\" class=\"data row125 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row125_col2\" class=\"data row125 col2\" ><a href=\"https://arxiv.org/abs/2003.07158\">https://arxiv.org/abs/2003.07158</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row126\" class=\"row_heading level0 row126\" >126</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row126_col0\" class=\"data row126 col0\" >Improving Perceptual Quality of Drum Transcription with the Expanded  Groove MIDI Dataset</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row126_col1\" class=\"data row126 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row126_col2\" class=\"data row126 col2\" ><a href=\"https://arxiv.org/abs/2004.00188\">https://arxiv.org/abs/2004.00188</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row127\" class=\"row_heading level0 row127\" >127</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row127_col0\" class=\"data row127 col0\" >No-regret learning dynamics for extensive-form correlated and coarse  correlated equilibria</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row127_col1\" class=\"data row127 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row127_col2\" class=\"data row127 col2\" ><a href=\"https://arxiv.org/abs/2004.00603\">https://arxiv.org/abs/2004.00603</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row128\" class=\"row_heading level0 row128\" >128</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row128_col0\" class=\"data row128 col0\" >Towards Faithfully Interpretable NLP Systems: How should we define and  evaluate faithfulness?</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row128_col1\" class=\"data row128 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row128_col2\" class=\"data row128 col2\" ><a href=\"https://arxiv.org/abs/2004.03685\">https://arxiv.org/abs/2004.03685</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002level0_row129\" class=\"row_heading level0 row129\" >129</th>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row129_col0\" class=\"data row129 col0\" >Probabilistic embeddings for speaker diarization</td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row129_col1\" class=\"data row129 col1\" ></td>\n",
              "                        <td id=\"T_846793e0_7c32_11ea_8655_0242ac1c0002row129_col2\" class=\"data row129 col2\" ><a href=\"https://arxiv.org/abs/2004.04096\">https://arxiv.org/abs/2004.04096</a></td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fd7d85a3d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi6oqcu611k_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00d54d1b-16c5-4a12-8128-1b75d40a435f"
      },
      "source": [
        "LG.shape"
      ],
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(130, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 435
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTKQAAmqzK7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, row in LG.iterrows():\n",
        "    x = []\n",
        "    for keyword in my_keywordsLG:\n",
        "        x = x + re.findall(keyword, row['Title'] + row['Abstract'])\n",
        "    if not x:\n",
        "        LG.drop([i], axis=0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSYlPaMw1lKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "c23fb7aa-54fb-43c5-901f-2b73fdb9fb55"
      },
      "source": [
        "LG.style.format({\"Link\": lambda x: '<a href=\"{}\">{}</a>'.format(x, x)})"
      ],
      "execution_count": 437,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_8488b110_7c32_11ea_8655_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Title</th>        <th class=\"col_heading level0 col1\" >Abstract</th>        <th class=\"col_heading level0 col2\" >Link</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_8488b110_7c32_11ea_8655_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >54</th>\n",
              "                        <td id=\"T_8488b110_7c32_11ea_8655_0242ac1c0002row0_col0\" class=\"data row0 col0\" >Calibrating Structured Output Predictors for Natural Language Processing</td>\n",
              "                        <td id=\"T_8488b110_7c32_11ea_8655_0242ac1c0002row0_col1\" class=\"data row0 col1\" >We address the problem of calibrating prediction confidence for output\n",
              "entities of interest in natural language processing (NLP) applications. It is\n",
              "important that NLP applications such as named entity recognition and question\n",
              "answering produce calibrated confidence scores for their predictions,\n",
              "especially if the system is to be deployed in a safety-critical domain such as\n",
              "healthcare. However, the output space of such structured prediction models is\n",
              "often too large to adapt binary or multi-class calibration methods directly. In\n",
              "this study, we propose a general calibration scheme for output entities of\n",
              "interest in neural-network based structured prediction models. Our proposed\n",
              "method can be used with any binary class calibration scheme and a neural\n",
              "network model. Additionally, we show that our calibration method can also be\n",
              "used as an uncertainty-aware, entity-specific decoding step to improve the\n",
              "performance of the underlying model at no additional training cost or data\n",
              "requirements. We show that our method outperforms current calibration\n",
              "techniques for named-entity-recognition, part-of-speech and question answering.\n",
              "We also improve our model's performance from our decoding step across several\n",
              "tasks and benchmark datasets. Our method improves the calibration and model\n",
              "performance on out-of-domain test scenarios as well.\n",
              "</td>\n",
              "                        <td id=\"T_8488b110_7c32_11ea_8655_0242ac1c0002row0_col2\" class=\"data row0 col2\" ><a href=\"https://arxiv.org/abs/2004.04361\">https://arxiv.org/abs/2004.04361</a></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_8488b110_7c32_11ea_8655_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >128</th>\n",
              "                        <td id=\"T_8488b110_7c32_11ea_8655_0242ac1c0002row1_col0\" class=\"data row1 col0\" >Towards Faithfully Interpretable NLP Systems: How should we define and  evaluate faithfulness?</td>\n",
              "                        <td id=\"T_8488b110_7c32_11ea_8655_0242ac1c0002row1_col1\" class=\"data row1 col1\" ></td>\n",
              "                        <td id=\"T_8488b110_7c32_11ea_8655_0242ac1c0002row1_col2\" class=\"data row1 col2\" ><a href=\"https://arxiv.org/abs/2004.03685\">https://arxiv.org/abs/2004.03685</a></td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fd7d779ab00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 437
        }
      ]
    }
  ]
}